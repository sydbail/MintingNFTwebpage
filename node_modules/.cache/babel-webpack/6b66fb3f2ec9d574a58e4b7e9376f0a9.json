{"ast":null,"code":"'use strict';\n\nvar _asyncToGenerator = require(\"/Users/sydneybailey/Internship/Dapp/node_modules/@babel/runtime/helpers/asyncToGenerator\").default;\n\nvar _asyncGeneratorDelegate = require(\"/Users/sydneybailey/Internship/Dapp/node_modules/@babel/runtime/helpers/asyncGeneratorDelegate\").default;\n\nvar _asyncIterator = require(\"/Users/sydneybailey/Internship/Dapp/node_modules/@babel/runtime/helpers/asyncIterator\").default;\n\nvar _awaitAsyncGenerator = require(\"/Users/sydneybailey/Internship/Dapp/node_modules/@babel/runtime/helpers/awaitAsyncGenerator\").default;\n\nvar _wrapAsyncGenerator = require(\"/Users/sydneybailey/Internship/Dapp/node_modules/@babel/runtime/helpers/wrapAsyncGenerator\").default;\n\nconst log = require('debug')('ipfs:mfs:write');\n\nconst {\n  importer\n} = require('ipfs-unixfs-importer');\n\nconst {\n  decode // @ts-ignore - TODO vmx 2021-03-31\n\n} = require('@ipld/dag-pb');\n\nconst {\n  sha256,\n  sha512\n} = require('multiformats/hashes/sha2');\n\nconst stat = require('./stat');\n\nconst mkdir = require('./mkdir');\n\nconst addLink = require('./utils/add-link');\n\nconst mergeOptions = require('merge-options').bind({\n  ignoreUndefined: true\n});\n\nconst createLock = require('./utils/create-lock');\n\nconst toAsyncIterator = require('./utils/to-async-iterator');\n\nconst toMfsPath = require('./utils/to-mfs-path');\n\nconst toPathComponents = require('./utils/to-path-components');\n\nconst toTrail = require('./utils/to-trail');\n\nconst updateTree = require('./utils/update-tree');\n\nconst updateMfsRoot = require('./utils/update-mfs-root');\n\nconst errCode = require('err-code');\n\nconst {\n  MFS_MAX_CHUNK_SIZE\n} = require('../../utils');\n\nconst last = require('it-last');\n\nconst withTimeoutOption = require('ipfs-core-utils/src/with-timeout-option');\n\nconst {\n  parseMode,\n  parseMtime\n} = require('ipfs-unixfs');\n/**\n * @typedef {import('multiformats/cid').CIDVersion} CIDVersion\n * @typedef {import('ipfs-unixfs').MtimeLike} MtimeLike\n * @typedef {import('./').MfsContext} MfsContext\n * @typedef {import('./utils/to-mfs-path').FilePath} FilePath\n * @typedef {import('./utils/to-mfs-path').MfsPath} MfsPath\n * @typedef {import('multiformats/hashes/interface').MultihashHasher} MultihashHasher\n *\n * @typedef {object} DefaultOptions\n * @property {number} offset\n * @property {number} length\n * @property {boolean} create\n * @property {boolean} truncate\n * @property {boolean} rawLeaves\n * @property {boolean} reduceSingleLeafToSelf\n * @property {CIDVersion} cidVersion\n * @property {string} hashAlg\n * @property {boolean} parents\n * @property {import('ipfs-core-types/src/root').AddProgressFn} progress\n * @property {'trickle' | 'balanced'} strategy\n * @property {boolean} flush\n * @property {'raw' | 'file'} leafType\n * @property {number} shardSplitThreshold\n * @property {MtimeLike} [mtime]\n * @property {number} [mode]\n * @property {AbortSignal} [signal]\n * @property {number} [timeout]\n */\n\n/**\n * @type {DefaultOptions}\n */\n\n\nconst defaultOptions = {\n  offset: 0,\n  // the offset in the file to begin writing\n  length: Infinity,\n  // how many bytes from the incoming buffer to write\n  create: false,\n  // whether to create the file if it does not exist\n  truncate: false,\n  // whether to truncate the file first\n  rawLeaves: false,\n  reduceSingleLeafToSelf: false,\n  cidVersion: 0,\n  hashAlg: 'sha2-256',\n  parents: false,\n  // whether to create intermediate directories if they do not exist\n  progress: (bytes, path) => {},\n  strategy: 'trickle',\n  flush: true,\n  leafType: 'raw',\n  shardSplitThreshold: 1000\n};\n/**\n * @param {MfsContext} context\n */\n\nmodule.exports = context => {\n  /**\n   * @type {import('ipfs-core-types/src/files').API[\"write\"]}\n   */\n  function mfsWrite(_x4, _x5) {\n    return _mfsWrite.apply(this, arguments);\n  }\n\n  function _mfsWrite() {\n    _mfsWrite = _asyncToGenerator(function* (path, content, opts = {}) {\n      /** @type {DefaultOptions} */\n      const options = mergeOptions(defaultOptions, opts);\n      /** @type {AsyncIterable<Uint8Array>} */\n\n      let source;\n      /** @type {MfsPath} */\n\n      let destination;\n      /** @type {MfsPath} */\n\n      let parent;\n      log('Reading source, destination and parent');\n      yield createLock().readLock( /*#__PURE__*/_asyncToGenerator(function* () {\n        source = yield toAsyncIterator(content);\n        destination = yield toMfsPath(context, path, options);\n        parent = yield toMfsPath(context, destination.mfsDirectory, options);\n      }))();\n      log('Read source, destination and parent'); // @ts-ignore - parent may be undefined\n\n      if (!options.parents && !parent.exists) {\n        throw errCode(new Error('directory does not exist'), 'ERR_NO_EXIST');\n      } // @ts-ignore\n\n\n      if (source == null) {\n        throw errCode(new Error('could not create source'), 'ERR_NO_SOURCE');\n      } // @ts-ignore\n\n\n      if (destination == null) {\n        throw errCode(new Error('could not create destination'), 'ERR_NO_DESTINATION');\n      }\n\n      if (!options.create && !destination.exists) {\n        throw errCode(new Error('file does not exist'), 'ERR_NO_EXIST');\n      }\n\n      if (destination.entryType !== 'file') {\n        throw errCode(new Error('not a file'), 'ERR_NOT_A_FILE');\n      }\n\n      return updateOrImport(context, path, source, destination, options);\n    });\n    return _mfsWrite.apply(this, arguments);\n  }\n\n  return withTimeoutOption(mfsWrite);\n};\n/**\n * @param {MfsContext} context\n * @param {string} path\n * @param {AsyncIterable<Uint8Array>} source\n * @param {FilePath} destination\n * @param {DefaultOptions} options\n */\n\n\nconst updateOrImport = /*#__PURE__*/function () {\n  var _ref5 = _asyncToGenerator(function* (context, path, source, destination, options) {\n    const child = yield write(context, source, destination, options); // The slow bit is done, now add or replace the DAGLink in the containing directory\n    // re-reading the path to the containing folder in case it has changed in the interim\n\n    yield createLock().writeLock( /*#__PURE__*/_asyncToGenerator(function* () {\n      const pathComponents = toPathComponents(path);\n      const fileName = pathComponents.pop();\n\n      if (fileName == null) {\n        throw errCode(new Error('source does not exist'), 'ERR_NO_EXIST');\n      }\n\n      let parentExists = false;\n\n      try {\n        yield stat(context)(`/${pathComponents.join('/')}`, options);\n        parentExists = true;\n      } catch (err) {\n        if (err.code !== 'ERR_NOT_FOUND') {\n          throw err;\n        }\n      }\n\n      if (!parentExists) {\n        yield mkdir(context)(`/${pathComponents.join('/')}`, options);\n      } // get an updated mfs path in case the root changed while we were writing\n\n\n      const updatedPath = yield toMfsPath(context, path, options);\n      const trail = yield toTrail(context, updatedPath.mfsDirectory);\n      const parent = trail[trail.length - 1];\n\n      if (!parent) {\n        throw errCode(new Error('directory does not exist'), 'ERR_NO_EXIST');\n      }\n\n      if (!parent.type || !parent.type.includes('directory')) {\n        throw errCode(new Error(`cannot write to ${parent.name}: Not a directory`), 'ERR_NOT_A_DIRECTORY');\n      }\n\n      const parentBlock = yield context.repo.blocks.get(parent.cid);\n      const parentNode = decode(parentBlock);\n      const result = yield addLink(context, {\n        parent: parentNode,\n        name: fileName,\n        cid: child.cid,\n        size: child.size,\n        flush: options.flush,\n        shardSplitThreshold: options.shardSplitThreshold,\n        hashAlg: options.hashAlg,\n        cidVersion: options.cidVersion\n      });\n      parent.cid = result.cid; // update the tree with the new child\n\n      const newRootCid = yield updateTree(context, trail, options); // Update the MFS record with the new CID for the root of the tree\n\n      yield updateMfsRoot(context, newRootCid, options);\n    }))();\n  });\n\n  return function updateOrImport(_x6, _x7, _x8, _x9, _x10) {\n    return _ref5.apply(this, arguments);\n  };\n}();\n/**\n * @param {MfsContext} context\n * @param {AsyncIterable<Uint8Array>} source\n * @param {FilePath} destination\n * @param {DefaultOptions} options\n */\n\n\nconst write = /*#__PURE__*/function () {\n  var _ref7 = _asyncToGenerator(function* (context, source, destination, options) {\n    if (destination.exists) {\n      log(`Overwriting file ${destination.cid} offset ${options.offset} length ${options.length}`);\n    } else {\n      log(`Writing file offset ${options.offset} length ${options.length}`);\n    }\n    /** @type {Array<() => AsyncIterable<Uint8Array>>} */\n\n\n    const sources = []; // pad start of file if necessary\n\n    if (options.offset > 0) {\n      if (destination.unixfs) {\n        log(`Writing first ${options.offset} bytes of original file`);\n        sources.push(() => {\n          return destination.content({\n            offset: 0,\n            length: options.offset\n          });\n        });\n\n        if (destination.unixfs.fileSize() < options.offset) {\n          const extra = options.offset - destination.unixfs.fileSize();\n          log(`Writing zeros for extra ${extra} bytes`);\n          sources.push(asyncZeroes(extra));\n        }\n      } else {\n        log(`Writing zeros for first ${options.offset} bytes`);\n        sources.push(asyncZeroes(options.offset));\n      }\n    }\n\n    sources.push(limitAsyncStreamBytes(source, options.length));\n    const content = countBytesStreamed(catAsyncIterators(sources), bytesWritten => {\n      if (destination.unixfs && !options.truncate) {\n        // if we've done reading from the new source and we are not going\n        // to truncate the file, add the end of the existing file to the output\n        const fileSize = destination.unixfs.fileSize();\n\n        if (fileSize > bytesWritten) {\n          log(`Writing last ${fileSize - bytesWritten} of ${fileSize} bytes from original file starting at offset ${bytesWritten}`);\n          return destination.content({\n            offset: bytesWritten\n          });\n        } else {\n          log('Not writing last bytes from original file');\n        }\n      }\n\n      return {\n        [Symbol.asyncIterator]: _wrapAsyncGenerator(function* () {})\n      };\n    });\n    /** @type {number | undefined} */\n\n    let mode;\n\n    if (options.mode !== undefined && options.mode !== null) {\n      mode = parseMode(options.mode);\n    } else if (destination && destination.unixfs) {\n      mode = destination.unixfs.mode;\n    }\n    /** @type {import('ipfs-unixfs').Mtime | undefined} */\n\n\n    let mtime;\n\n    if (options.mtime != null) {\n      mtime = parseMtime(options.mtime);\n    } else if (destination && destination.unixfs) {\n      mtime = destination.unixfs.mtime;\n    }\n\n    let hasher;\n\n    switch (options.hashAlg) {\n      case 'sha2-256':\n        hasher = sha256;\n        break;\n\n      case 'sha2-512':\n        hasher = sha512;\n        break;\n\n      default:\n        throw new Error(`TODO vmx 2021-03-31: Proper error message for unsupported hash algorithms like ${options.hashAlg}`);\n    }\n\n    const result = yield last(importer([{\n      content: content,\n      // persist mode & mtime if set previously\n      mode,\n      mtime\n    }], context.repo.blocks, {\n      progress: options.progress,\n      hasher,\n      cidVersion: options.cidVersion,\n      strategy: options.strategy,\n      rawLeaves: options.rawLeaves,\n      reduceSingleLeafToSelf: options.reduceSingleLeafToSelf,\n      leafType: options.leafType\n    }));\n\n    if (!result) {\n      throw errCode(new Error(`cannot write to ${parent.name}`), 'ERR_COULD_NOT_WRITE');\n    }\n\n    log(`Wrote ${result.cid}`);\n    return {\n      cid: result.cid,\n      size: result.size\n    };\n  });\n\n  return function write(_x11, _x12, _x13, _x14) {\n    return _ref7.apply(this, arguments);\n  };\n}();\n/**\n * @param {AsyncIterable<Uint8Array>} stream\n * @param {number} limit\n */\n\n\nconst limitAsyncStreamBytes = (stream, limit) => {\n  return /*#__PURE__*/function () {\n    var _limitAsyncStreamBytes2 = _wrapAsyncGenerator(function* () {\n      let emitted = 0;\n      var _iteratorNormalCompletion = true;\n      var _didIteratorError = false;\n\n      var _iteratorError;\n\n      try {\n        for (var _iterator = _asyncIterator(stream), _step, _value; _step = yield _awaitAsyncGenerator(_iterator.next()), _iteratorNormalCompletion = _step.done, _value = yield _awaitAsyncGenerator(_step.value), !_iteratorNormalCompletion; _iteratorNormalCompletion = true) {\n          const buf = _value;\n          emitted += buf.length;\n\n          if (emitted > limit) {\n            yield buf.slice(0, limit - emitted);\n            return;\n          }\n\n          yield buf;\n        }\n      } catch (err) {\n        _didIteratorError = true;\n        _iteratorError = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion && _iterator.return != null) {\n            yield _awaitAsyncGenerator(_iterator.return());\n          }\n        } finally {\n          if (_didIteratorError) {\n            throw _iteratorError;\n          }\n        }\n      }\n    });\n\n    function _limitAsyncStreamBytes() {\n      return _limitAsyncStreamBytes2.apply(this, arguments);\n    }\n\n    return _limitAsyncStreamBytes;\n  }();\n};\n/**\n * @param {number} count\n * @param {number} chunkSize\n */\n\n\nconst asyncZeroes = (count, chunkSize = MFS_MAX_CHUNK_SIZE) => {\n  const buf = new Uint8Array(chunkSize);\n\n  function _asyncZeroes() {\n    return _asyncZeroes2.apply(this, arguments);\n  }\n\n  function _asyncZeroes2() {\n    _asyncZeroes2 = _wrapAsyncGenerator(function* () {\n      while (true) {\n        yield buf.slice();\n      }\n    });\n    return _asyncZeroes2.apply(this, arguments);\n  }\n\n  return limitAsyncStreamBytes(_asyncZeroes(), count);\n};\n/**\n * @param {Array<() => AsyncIterable<Uint8Array>>} sources\n */\n\n\nconst catAsyncIterators = /*#__PURE__*/function () {\n  var _ref2 = _wrapAsyncGenerator(function* (sources) {\n    // eslint-disable-line require-await\n    for (let i = 0; i < sources.length; i++) {\n      yield* _asyncGeneratorDelegate(_asyncIterator(sources[i]()), _awaitAsyncGenerator);\n    }\n  });\n\n  return function catAsyncIterators(_x) {\n    return _ref2.apply(this, arguments);\n  };\n}();\n/**\n * @param {AsyncIterable<Uint8Array>} source\n * @param {(count: number) => AsyncIterable<Uint8Array>} notify\n */\n\n\nconst countBytesStreamed = /*#__PURE__*/function () {\n  var _ref3 = _wrapAsyncGenerator(function* (source, notify) {\n    let wrote = 0;\n    var _iteratorNormalCompletion2 = true;\n    var _didIteratorError2 = false;\n\n    var _iteratorError2;\n\n    try {\n      for (var _iterator2 = _asyncIterator(source), _step2, _value2; _step2 = yield _awaitAsyncGenerator(_iterator2.next()), _iteratorNormalCompletion2 = _step2.done, _value2 = yield _awaitAsyncGenerator(_step2.value), !_iteratorNormalCompletion2; _iteratorNormalCompletion2 = true) {\n        const buf = _value2;\n        wrote += buf.length;\n        yield buf;\n      }\n    } catch (err) {\n      _didIteratorError2 = true;\n      _iteratorError2 = err;\n    } finally {\n      try {\n        if (!_iteratorNormalCompletion2 && _iterator2.return != null) {\n          yield _awaitAsyncGenerator(_iterator2.return());\n        }\n      } finally {\n        if (_didIteratorError2) {\n          throw _iteratorError2;\n        }\n      }\n    }\n\n    var _iteratorNormalCompletion3 = true;\n    var _didIteratorError3 = false;\n\n    var _iteratorError3;\n\n    try {\n      for (var _iterator3 = _asyncIterator(notify(wrote)), _step3, _value3; _step3 = yield _awaitAsyncGenerator(_iterator3.next()), _iteratorNormalCompletion3 = _step3.done, _value3 = yield _awaitAsyncGenerator(_step3.value), !_iteratorNormalCompletion3; _iteratorNormalCompletion3 = true) {\n        const buf = _value3;\n        wrote += buf.length;\n        yield buf;\n      }\n    } catch (err) {\n      _didIteratorError3 = true;\n      _iteratorError3 = err;\n    } finally {\n      try {\n        if (!_iteratorNormalCompletion3 && _iterator3.return != null) {\n          yield _awaitAsyncGenerator(_iterator3.return());\n        }\n      } finally {\n        if (_didIteratorError3) {\n          throw _iteratorError3;\n        }\n      }\n    }\n  });\n\n  return function countBytesStreamed(_x2, _x3) {\n    return _ref3.apply(this, arguments);\n  };\n}();","map":{"version":3,"sources":["/Users/sydneybailey/Internship/Dapp/node_modules/ipfs-core/src/components/files/write.js"],"names":["log","require","importer","decode","sha256","sha512","stat","mkdir","addLink","mergeOptions","bind","ignoreUndefined","createLock","toAsyncIterator","toMfsPath","toPathComponents","toTrail","updateTree","updateMfsRoot","errCode","MFS_MAX_CHUNK_SIZE","last","withTimeoutOption","parseMode","parseMtime","defaultOptions","offset","length","Infinity","create","truncate","rawLeaves","reduceSingleLeafToSelf","cidVersion","hashAlg","parents","progress","bytes","path","strategy","flush","leafType","shardSplitThreshold","module","exports","context","mfsWrite","content","opts","options","source","destination","parent","readLock","mfsDirectory","exists","Error","entryType","updateOrImport","child","write","writeLock","pathComponents","fileName","pop","parentExists","join","err","code","updatedPath","trail","type","includes","name","parentBlock","repo","blocks","get","cid","parentNode","result","size","newRootCid","sources","unixfs","push","fileSize","extra","asyncZeroes","limitAsyncStreamBytes","countBytesStreamed","catAsyncIterators","bytesWritten","Symbol","asyncIterator","mode","undefined","mtime","hasher","stream","limit","emitted","buf","slice","_limitAsyncStreamBytes","count","chunkSize","Uint8Array","_asyncZeroes","i","notify","wrote"],"mappings":"AAAA;;;;;;;;;;;;AAEA,MAAMA,GAAG,GAAGC,OAAO,CAAC,OAAD,CAAP,CAAiB,gBAAjB,CAAZ;;AACA,MAAM;AAAEC,EAAAA;AAAF,IAAeD,OAAO,CAAC,sBAAD,CAA5B;;AACA,MAAM;AACJE,EAAAA,MADI,CAEN;;AAFM,IAGFF,OAAO,CAAC,cAAD,CAHX;;AAIA,MAAM;AAAEG,EAAAA,MAAF;AAAUC,EAAAA;AAAV,IAAqBJ,OAAO,CAAC,0BAAD,CAAlC;;AACA,MAAMK,IAAI,GAAGL,OAAO,CAAC,QAAD,CAApB;;AACA,MAAMM,KAAK,GAAGN,OAAO,CAAC,SAAD,CAArB;;AACA,MAAMO,OAAO,GAAGP,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAMQ,YAAY,GAAGR,OAAO,CAAC,eAAD,CAAP,CAAyBS,IAAzB,CAA8B;AAAEC,EAAAA,eAAe,EAAE;AAAnB,CAA9B,CAArB;;AACA,MAAMC,UAAU,GAAGX,OAAO,CAAC,qBAAD,CAA1B;;AACA,MAAMY,eAAe,GAAGZ,OAAO,CAAC,2BAAD,CAA/B;;AACA,MAAMa,SAAS,GAAGb,OAAO,CAAC,qBAAD,CAAzB;;AACA,MAAMc,gBAAgB,GAAGd,OAAO,CAAC,4BAAD,CAAhC;;AACA,MAAMe,OAAO,GAAGf,OAAO,CAAC,kBAAD,CAAvB;;AACA,MAAMgB,UAAU,GAAGhB,OAAO,CAAC,qBAAD,CAA1B;;AACA,MAAMiB,aAAa,GAAGjB,OAAO,CAAC,yBAAD,CAA7B;;AACA,MAAMkB,OAAO,GAAGlB,OAAO,CAAC,UAAD,CAAvB;;AACA,MAAM;AACJmB,EAAAA;AADI,IAEFnB,OAAO,CAAC,aAAD,CAFX;;AAGA,MAAMoB,IAAI,GAAGpB,OAAO,CAAC,SAAD,CAApB;;AACA,MAAMqB,iBAAiB,GAAGrB,OAAO,CAAC,yCAAD,CAAjC;;AACA,MAAM;AACJsB,EAAAA,SADI;AAEJC,EAAAA;AAFI,IAGFvB,OAAO,CAAC,aAAD,CAHX;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;;AACA,MAAMwB,cAAc,GAAG;AACrBC,EAAAA,MAAM,EAAE,CADa;AACV;AACXC,EAAAA,MAAM,EAAEC,QAFa;AAEH;AAClBC,EAAAA,MAAM,EAAE,KAHa;AAGN;AACfC,EAAAA,QAAQ,EAAE,KAJW;AAIJ;AACjBC,EAAAA,SAAS,EAAE,KALU;AAMrBC,EAAAA,sBAAsB,EAAE,KANH;AAOrBC,EAAAA,UAAU,EAAE,CAPS;AAQrBC,EAAAA,OAAO,EAAE,UARY;AASrBC,EAAAA,OAAO,EAAE,KATY;AASL;AAChBC,EAAAA,QAAQ,EAAE,CAACC,KAAD,EAAQC,IAAR,KAAiB,CAAE,CAVR;AAWrBC,EAAAA,QAAQ,EAAE,SAXW;AAYrBC,EAAAA,KAAK,EAAE,IAZc;AAarBC,EAAAA,QAAQ,EAAE,KAbW;AAcrBC,EAAAA,mBAAmB,EAAE;AAdA,CAAvB;AAiBA;AACA;AACA;;AACAC,MAAM,CAACC,OAAP,GAAkBC,OAAD,IAAa;AAC5B;AACF;AACA;AAH8B,WAIbC,QAJa;AAAA;AAAA;;AAAA;AAAA,kCAI5B,WAAyBR,IAAzB,EAA+BS,OAA/B,EAAwCC,IAAI,GAAG,EAA/C,EAAmD;AACjD;AACA,YAAMC,OAAO,GAAGxC,YAAY,CAACgB,cAAD,EAAiBuB,IAAjB,CAA5B;AAEA;;AACA,UAAIE,MAAJ;AACA;;AACA,UAAIC,WAAJ;AACA;;AACA,UAAIC,MAAJ;AACApD,MAAAA,GAAG,CAAC,wCAAD,CAAH;AACA,YAAMY,UAAU,GAAGyC,QAAb,iCAAsB,aAAY;AACtCH,QAAAA,MAAM,SAASrC,eAAe,CAACkC,OAAD,CAA9B;AACAI,QAAAA,WAAW,SAASrC,SAAS,CAAC+B,OAAD,EAAUP,IAAV,EAAgBW,OAAhB,CAA7B;AACAG,QAAAA,MAAM,SAAStC,SAAS,CAAC+B,OAAD,EAAUM,WAAW,CAACG,YAAtB,EAAoCL,OAApC,CAAxB;AACD,OAJK,IAAN;AAKAjD,MAAAA,GAAG,CAAC,qCAAD,CAAH,CAhBiD,CAiBjD;;AACA,UAAI,CAACiD,OAAO,CAACd,OAAT,IAAoB,CAACiB,MAAM,CAACG,MAAhC,EAAwC;AACtC,cAAMpC,OAAO,CAAC,IAAIqC,KAAJ,CAAU,0BAAV,CAAD,EAAwC,cAAxC,CAAb;AACD,OApBgD,CAsBjD;;;AACA,UAAIN,MAAM,IAAI,IAAd,EAAoB;AAClB,cAAM/B,OAAO,CAAC,IAAIqC,KAAJ,CAAU,yBAAV,CAAD,EAAuC,eAAvC,CAAb;AACD,OAzBgD,CA2BjD;;;AACA,UAAIL,WAAW,IAAI,IAAnB,EAAyB;AACvB,cAAMhC,OAAO,CAAC,IAAIqC,KAAJ,CAAU,8BAAV,CAAD,EAA4C,oBAA5C,CAAb;AACD;;AAED,UAAI,CAACP,OAAO,CAACpB,MAAT,IAAmB,CAACsB,WAAW,CAACI,MAApC,EAA4C;AAC1C,cAAMpC,OAAO,CAAC,IAAIqC,KAAJ,CAAU,qBAAV,CAAD,EAAmC,cAAnC,CAAb;AACD;;AAED,UAAIL,WAAW,CAACM,SAAZ,KAA0B,MAA9B,EAAsC;AACpC,cAAMtC,OAAO,CAAC,IAAIqC,KAAJ,CAAU,YAAV,CAAD,EAA0B,gBAA1B,CAAb;AACD;;AAED,aAAOE,cAAc,CAACb,OAAD,EAAUP,IAAV,EAAgBY,MAAhB,EAAwBC,WAAxB,EAAqCF,OAArC,CAArB;AACD,KA7C2B;AAAA;AAAA;;AA+C5B,SAAO3B,iBAAiB,CAACwB,QAAD,CAAxB;AACD,CAhDD;AAkDA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMY,cAAc;AAAA,gCAAG,WAAOb,OAAP,EAAgBP,IAAhB,EAAsBY,MAAtB,EAA8BC,WAA9B,EAA2CF,OAA3C,EAAuD;AAC5E,UAAMU,KAAK,SAASC,KAAK,CAACf,OAAD,EAAUK,MAAV,EAAkBC,WAAlB,EAA+BF,OAA/B,CAAzB,CAD4E,CAG5E;AACA;;AACA,UAAMrC,UAAU,GAAGiD,SAAb,iCAAuB,aAAY;AACvC,YAAMC,cAAc,GAAG/C,gBAAgB,CAACuB,IAAD,CAAvC;AACA,YAAMyB,QAAQ,GAAGD,cAAc,CAACE,GAAf,EAAjB;;AAEA,UAAID,QAAQ,IAAI,IAAhB,EAAsB;AACpB,cAAM5C,OAAO,CAAC,IAAIqC,KAAJ,CAAU,uBAAV,CAAD,EAAqC,cAArC,CAAb;AACD;;AAED,UAAIS,YAAY,GAAG,KAAnB;;AAEA,UAAI;AACF,cAAM3D,IAAI,CAACuC,OAAD,CAAJ,CAAe,IAAGiB,cAAc,CAACI,IAAf,CAAoB,GAApB,CAAyB,EAA3C,EAA8CjB,OAA9C,CAAN;AACAgB,QAAAA,YAAY,GAAG,IAAf;AACD,OAHD,CAGE,OAAOE,GAAP,EAAY;AACZ,YAAIA,GAAG,CAACC,IAAJ,KAAa,eAAjB,EAAkC;AAChC,gBAAMD,GAAN;AACD;AACF;;AAED,UAAI,CAACF,YAAL,EAAmB;AACjB,cAAM1D,KAAK,CAACsC,OAAD,CAAL,CAAgB,IAAGiB,cAAc,CAACI,IAAf,CAAoB,GAApB,CAAyB,EAA5C,EAA+CjB,OAA/C,CAAN;AACD,OArBsC,CAuBvC;;;AACA,YAAMoB,WAAW,SAASvD,SAAS,CAAC+B,OAAD,EAAUP,IAAV,EAAgBW,OAAhB,CAAnC;AACA,YAAMqB,KAAK,SAAStD,OAAO,CAAC6B,OAAD,EAAUwB,WAAW,CAACf,YAAtB,CAA3B;AACA,YAAMF,MAAM,GAAGkB,KAAK,CAACA,KAAK,CAAC3C,MAAN,GAAe,CAAhB,CAApB;;AAEA,UAAI,CAACyB,MAAL,EAAa;AACX,cAAMjC,OAAO,CAAC,IAAIqC,KAAJ,CAAU,0BAAV,CAAD,EAAwC,cAAxC,CAAb;AACD;;AAED,UAAI,CAACJ,MAAM,CAACmB,IAAR,IAAgB,CAACnB,MAAM,CAACmB,IAAP,CAAYC,QAAZ,CAAqB,WAArB,CAArB,EAAwD;AACtD,cAAMrD,OAAO,CAAC,IAAIqC,KAAJ,CAAW,mBAAkBJ,MAAM,CAACqB,IAAK,mBAAzC,CAAD,EAA+D,qBAA/D,CAAb;AACD;;AAED,YAAMC,WAAW,SAAS7B,OAAO,CAAC8B,IAAR,CAAaC,MAAb,CAAoBC,GAApB,CAAwBzB,MAAM,CAAC0B,GAA/B,CAA1B;AACA,YAAMC,UAAU,GAAG5E,MAAM,CAACuE,WAAD,CAAzB;AAEA,YAAMM,MAAM,SAASxE,OAAO,CAACqC,OAAD,EAAU;AACpCO,QAAAA,MAAM,EAAE2B,UAD4B;AAEpCN,QAAAA,IAAI,EAAEV,QAF8B;AAGpCe,QAAAA,GAAG,EAAEnB,KAAK,CAACmB,GAHyB;AAIpCG,QAAAA,IAAI,EAAEtB,KAAK,CAACsB,IAJwB;AAKpCzC,QAAAA,KAAK,EAAES,OAAO,CAACT,KALqB;AAMpCE,QAAAA,mBAAmB,EAAEO,OAAO,CAACP,mBANO;AAOpCR,QAAAA,OAAO,EAAEe,OAAO,CAACf,OAPmB;AAQpCD,QAAAA,UAAU,EAAEgB,OAAO,CAAChB;AARgB,OAAV,CAA5B;AAWAmB,MAAAA,MAAM,CAAC0B,GAAP,GAAaE,MAAM,CAACF,GAApB,CAlDuC,CAoDvC;;AACA,YAAMI,UAAU,SAASjE,UAAU,CAAC4B,OAAD,EAAUyB,KAAV,EAAiBrB,OAAjB,CAAnC,CArDuC,CAuDvC;;AACA,YAAM/B,aAAa,CAAC2B,OAAD,EAAUqC,UAAV,EAAsBjC,OAAtB,CAAnB;AACD,KAzDK,IAAN;AA0DD,GA/DmB;;AAAA,kBAAdS,cAAc;AAAA;AAAA;AAAA,GAApB;AAiEA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAME,KAAK;AAAA,gCAAG,WAAOf,OAAP,EAAgBK,MAAhB,EAAwBC,WAAxB,EAAqCF,OAArC,EAAiD;AAC7D,QAAIE,WAAW,CAACI,MAAhB,EAAwB;AACtBvD,MAAAA,GAAG,CAAE,oBAAmBmD,WAAW,CAAC2B,GAAI,WAAU7B,OAAO,CAACvB,MAAO,WAAUuB,OAAO,CAACtB,MAAO,EAAvF,CAAH;AACD,KAFD,MAEO;AACL3B,MAAAA,GAAG,CAAE,uBAAsBiD,OAAO,CAACvB,MAAO,WAAUuB,OAAO,CAACtB,MAAO,EAAhE,CAAH;AACD;AAED;;;AACA,UAAMwD,OAAO,GAAG,EAAhB,CAR6D,CAU7D;;AACA,QAAIlC,OAAO,CAACvB,MAAR,GAAiB,CAArB,EAAwB;AACtB,UAAIyB,WAAW,CAACiC,MAAhB,EAAwB;AACtBpF,QAAAA,GAAG,CAAE,iBAAgBiD,OAAO,CAACvB,MAAO,yBAAjC,CAAH;AAEAyD,QAAAA,OAAO,CAACE,IAAR,CACE,MAAM;AACJ,iBAAOlC,WAAW,CAACJ,OAAZ,CAAoB;AACzBrB,YAAAA,MAAM,EAAE,CADiB;AAEzBC,YAAAA,MAAM,EAAEsB,OAAO,CAACvB;AAFS,WAApB,CAAP;AAID,SANH;;AASA,YAAIyB,WAAW,CAACiC,MAAZ,CAAmBE,QAAnB,KAAgCrC,OAAO,CAACvB,MAA5C,EAAoD;AAClD,gBAAM6D,KAAK,GAAGtC,OAAO,CAACvB,MAAR,GAAiByB,WAAW,CAACiC,MAAZ,CAAmBE,QAAnB,EAA/B;AAEAtF,UAAAA,GAAG,CAAE,2BAA0BuF,KAAM,QAAlC,CAAH;AACAJ,UAAAA,OAAO,CAACE,IAAR,CACEG,WAAW,CAACD,KAAD,CADb;AAGD;AACF,OApBD,MAoBO;AACLvF,QAAAA,GAAG,CAAE,2BAA0BiD,OAAO,CAACvB,MAAO,QAA3C,CAAH;AACAyD,QAAAA,OAAO,CAACE,IAAR,CACEG,WAAW,CAACvC,OAAO,CAACvB,MAAT,CADb;AAGD;AACF;;AAEDyD,IAAAA,OAAO,CAACE,IAAR,CACEI,qBAAqB,CAACvC,MAAD,EAASD,OAAO,CAACtB,MAAjB,CADvB;AAIA,UAAMoB,OAAO,GAAG2C,kBAAkB,CAACC,iBAAiB,CAACR,OAAD,CAAlB,EAA8BS,YAAD,IAAkB;AAC/E,UAAIzC,WAAW,CAACiC,MAAZ,IAAsB,CAACnC,OAAO,CAACnB,QAAnC,EAA6C;AAC3C;AACA;AACA,cAAMwD,QAAQ,GAAGnC,WAAW,CAACiC,MAAZ,CAAmBE,QAAnB,EAAjB;;AAEA,YAAIA,QAAQ,GAAGM,YAAf,EAA6B;AAC3B5F,UAAAA,GAAG,CAAE,gBAAesF,QAAQ,GAAGM,YAAa,OAAMN,QAAS,gDAA+CM,YAAa,EAApH,CAAH;AAEA,iBAAOzC,WAAW,CAACJ,OAAZ,CAAoB;AACzBrB,YAAAA,MAAM,EAAEkE;AADiB,WAApB,CAAP;AAGD,SAND,MAMO;AACL5F,UAAAA,GAAG,CAAC,2CAAD,CAAH;AACD;AACF;;AAED,aAAO;AACL,SAAC6F,MAAM,CAACC,aAAR,uBAAwB,aAAoB,CAAE,CAA9C;AADK,OAAP;AAGD,KApBiC,CAAlC;AAsBA;;AACA,QAAIC,IAAJ;;AAEA,QAAI9C,OAAO,CAAC8C,IAAR,KAAiBC,SAAjB,IAA8B/C,OAAO,CAAC8C,IAAR,KAAiB,IAAnD,EAAyD;AACvDA,MAAAA,IAAI,GAAGxE,SAAS,CAAC0B,OAAO,CAAC8C,IAAT,CAAhB;AACD,KAFD,MAEO,IAAI5C,WAAW,IAAIA,WAAW,CAACiC,MAA/B,EAAuC;AAC5CW,MAAAA,IAAI,GAAG5C,WAAW,CAACiC,MAAZ,CAAmBW,IAA1B;AACD;AAED;;;AACA,QAAIE,KAAJ;;AAEA,QAAIhD,OAAO,CAACgD,KAAR,IAAiB,IAArB,EAA2B;AACzBA,MAAAA,KAAK,GAAGzE,UAAU,CAACyB,OAAO,CAACgD,KAAT,CAAlB;AACD,KAFD,MAEO,IAAI9C,WAAW,IAAIA,WAAW,CAACiC,MAA/B,EAAuC;AAC5Ca,MAAAA,KAAK,GAAG9C,WAAW,CAACiC,MAAZ,CAAmBa,KAA3B;AACD;;AAED,QAAIC,MAAJ;;AACA,YAAQjD,OAAO,CAACf,OAAhB;AACE,WAAK,UAAL;AACEgE,QAAAA,MAAM,GAAG9F,MAAT;AACA;;AACF,WAAK,UAAL;AACE8F,QAAAA,MAAM,GAAG7F,MAAT;AACA;;AACF;AACE,cAAM,IAAImD,KAAJ,CAAW,kFAAiFP,OAAO,CAACf,OAAQ,EAA5G,CAAN;AARJ;;AAWA,UAAM8C,MAAM,SAAS3D,IAAI,CAACnB,QAAQ,CAAC,CAAC;AAClC6C,MAAAA,OAAO,EAAEA,OADyB;AAGlC;AACAgD,MAAAA,IAJkC;AAKlCE,MAAAA;AALkC,KAAD,CAAD,EAM9BpD,OAAO,CAAC8B,IAAR,CAAaC,MANiB,EAMT;AACvBxC,MAAAA,QAAQ,EAAEa,OAAO,CAACb,QADK;AAEvB8D,MAAAA,MAFuB;AAGvBjE,MAAAA,UAAU,EAAEgB,OAAO,CAAChB,UAHG;AAIvBM,MAAAA,QAAQ,EAAEU,OAAO,CAACV,QAJK;AAKvBR,MAAAA,SAAS,EAAEkB,OAAO,CAAClB,SALI;AAMvBC,MAAAA,sBAAsB,EAAEiB,OAAO,CAACjB,sBANT;AAOvBS,MAAAA,QAAQ,EAAEQ,OAAO,CAACR;AAPK,KANS,CAAT,CAAzB;;AAgBA,QAAI,CAACuC,MAAL,EAAa;AACX,YAAM7D,OAAO,CAAC,IAAIqC,KAAJ,CAAW,mBAAkBJ,MAAM,CAACqB,IAAK,EAAzC,CAAD,EAA8C,qBAA9C,CAAb;AACD;;AAEDzE,IAAAA,GAAG,CAAE,SAAQgF,MAAM,CAACF,GAAI,EAArB,CAAH;AAEA,WAAO;AACLA,MAAAA,GAAG,EAAEE,MAAM,CAACF,GADP;AAELG,MAAAA,IAAI,EAAED,MAAM,CAACC;AAFR,KAAP;AAID,GA1HU;;AAAA,kBAALrB,KAAK;AAAA;AAAA;AAAA,GAAX;AA4HA;AACA;AACA;AACA;;;AACA,MAAM6B,qBAAqB,GAAG,CAACU,MAAD,EAASC,KAAT,KAAmB;AAC/C;AAAA,sDAAO,aAA2C;AAChD,UAAIC,OAAO,GAAG,CAAd;AADgD;AAAA;;AAAA;;AAAA;AAGhD,4CAAwBF,MAAxB,gOAAgC;AAAA,gBAAfG,GAAe;AAC9BD,UAAAA,OAAO,IAAIC,GAAG,CAAC3E,MAAf;;AAEA,cAAI0E,OAAO,GAAGD,KAAd,EAAqB;AACnB,kBAAME,GAAG,CAACC,KAAJ,CAAU,CAAV,EAAaH,KAAK,GAAGC,OAArB,CAAN;AAEA;AACD;;AAED,gBAAMC,GAAN;AACD;AAb+C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAcjD,KAdD;;AAAA,aAAwBE,sBAAxB;AAAA;AAAA;;AAAA,WAAwBA,sBAAxB;AAAA;AAeD,CAhBD;AAkBA;AACA;AACA;AACA;;;AACA,MAAMhB,WAAW,GAAG,CAACiB,KAAD,EAAQC,SAAS,GAAGtF,kBAApB,KAA2C;AAC7D,QAAMkF,GAAG,GAAG,IAAIK,UAAJ,CAAeD,SAAf,CAAZ;;AAD6D,WAG5CE,YAH4C;AAAA;AAAA;;AAAA;AAAA,wCAG7D,aAAiC;AAC/B,aAAO,IAAP,EAAa;AACX,cAAMN,GAAG,CAACC,KAAJ,EAAN;AACD;AACF,KAP4D;AAAA;AAAA;;AAS7D,SAAOd,qBAAqB,CAACmB,YAAY,EAAb,EAAiBH,KAAjB,CAA5B;AACD,CAVD;AAYA;AACA;AACA;;;AACA,MAAMd,iBAAiB;AAAA,kCAAG,WAAkBR,OAAlB,EAA2B;AAAE;AACrD,SAAK,IAAI0B,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG1B,OAAO,CAACxD,MAA5B,EAAoCkF,CAAC,EAArC,EAAyC;AACvC,oDAAQ1B,OAAO,CAAC0B,CAAD,CAAP,EAAR;AACD;AACF,GAJsB;;AAAA,kBAAjBlB,iBAAiB;AAAA;AAAA;AAAA,GAAvB;AAMA;AACA;AACA;AACA;;;AACA,MAAMD,kBAAkB;AAAA,kCAAG,WAAkBxC,MAAlB,EAA0B4D,MAA1B,EAAkC;AAC3D,QAAIC,KAAK,GAAG,CAAZ;AAD2D;AAAA;;AAAA;;AAAA;AAG3D,2CAAwB7D,MAAxB,0OAAgC;AAAA,cAAfoD,GAAe;AAC9BS,QAAAA,KAAK,IAAIT,GAAG,CAAC3E,MAAb;AAEA,cAAM2E,GAAN;AACD;AAP0D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;;AAAA;AAS3D,2CAAwBQ,MAAM,CAACC,KAAD,CAA9B,0OAAuC;AAAA,cAAtBT,GAAsB;AACrCS,QAAAA,KAAK,IAAIT,GAAG,CAAC3E,MAAb;AAEA,cAAM2E,GAAN;AACD;AAb0D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAc5D,GAduB;;AAAA,kBAAlBZ,kBAAkB;AAAA;AAAA;AAAA,GAAxB","sourcesContent":["'use strict'\n\nconst log = require('debug')('ipfs:mfs:write')\nconst { importer } = require('ipfs-unixfs-importer')\nconst {\n  decode\n// @ts-ignore - TODO vmx 2021-03-31\n} = require('@ipld/dag-pb')\nconst { sha256, sha512 } = require('multiformats/hashes/sha2')\nconst stat = require('./stat')\nconst mkdir = require('./mkdir')\nconst addLink = require('./utils/add-link')\nconst mergeOptions = require('merge-options').bind({ ignoreUndefined: true })\nconst createLock = require('./utils/create-lock')\nconst toAsyncIterator = require('./utils/to-async-iterator')\nconst toMfsPath = require('./utils/to-mfs-path')\nconst toPathComponents = require('./utils/to-path-components')\nconst toTrail = require('./utils/to-trail')\nconst updateTree = require('./utils/update-tree')\nconst updateMfsRoot = require('./utils/update-mfs-root')\nconst errCode = require('err-code')\nconst {\n  MFS_MAX_CHUNK_SIZE\n} = require('../../utils')\nconst last = require('it-last')\nconst withTimeoutOption = require('ipfs-core-utils/src/with-timeout-option')\nconst {\n  parseMode,\n  parseMtime\n} = require('ipfs-unixfs')\n\n/**\n * @typedef {import('multiformats/cid').CIDVersion} CIDVersion\n * @typedef {import('ipfs-unixfs').MtimeLike} MtimeLike\n * @typedef {import('./').MfsContext} MfsContext\n * @typedef {import('./utils/to-mfs-path').FilePath} FilePath\n * @typedef {import('./utils/to-mfs-path').MfsPath} MfsPath\n * @typedef {import('multiformats/hashes/interface').MultihashHasher} MultihashHasher\n *\n * @typedef {object} DefaultOptions\n * @property {number} offset\n * @property {number} length\n * @property {boolean} create\n * @property {boolean} truncate\n * @property {boolean} rawLeaves\n * @property {boolean} reduceSingleLeafToSelf\n * @property {CIDVersion} cidVersion\n * @property {string} hashAlg\n * @property {boolean} parents\n * @property {import('ipfs-core-types/src/root').AddProgressFn} progress\n * @property {'trickle' | 'balanced'} strategy\n * @property {boolean} flush\n * @property {'raw' | 'file'} leafType\n * @property {number} shardSplitThreshold\n * @property {MtimeLike} [mtime]\n * @property {number} [mode]\n * @property {AbortSignal} [signal]\n * @property {number} [timeout]\n */\n\n/**\n * @type {DefaultOptions}\n */\nconst defaultOptions = {\n  offset: 0, // the offset in the file to begin writing\n  length: Infinity, // how many bytes from the incoming buffer to write\n  create: false, // whether to create the file if it does not exist\n  truncate: false, // whether to truncate the file first\n  rawLeaves: false,\n  reduceSingleLeafToSelf: false,\n  cidVersion: 0,\n  hashAlg: 'sha2-256',\n  parents: false, // whether to create intermediate directories if they do not exist\n  progress: (bytes, path) => {},\n  strategy: 'trickle',\n  flush: true,\n  leafType: 'raw',\n  shardSplitThreshold: 1000\n}\n\n/**\n * @param {MfsContext} context\n */\nmodule.exports = (context) => {\n  /**\n   * @type {import('ipfs-core-types/src/files').API[\"write\"]}\n   */\n  async function mfsWrite (path, content, opts = {}) {\n    /** @type {DefaultOptions} */\n    const options = mergeOptions(defaultOptions, opts)\n\n    /** @type {AsyncIterable<Uint8Array>} */\n    let source\n    /** @type {MfsPath} */\n    let destination\n    /** @type {MfsPath} */\n    let parent\n    log('Reading source, destination and parent')\n    await createLock().readLock(async () => {\n      source = await toAsyncIterator(content)\n      destination = await toMfsPath(context, path, options)\n      parent = await toMfsPath(context, destination.mfsDirectory, options)\n    })()\n    log('Read source, destination and parent')\n    // @ts-ignore - parent may be undefined\n    if (!options.parents && !parent.exists) {\n      throw errCode(new Error('directory does not exist'), 'ERR_NO_EXIST')\n    }\n\n    // @ts-ignore\n    if (source == null) {\n      throw errCode(new Error('could not create source'), 'ERR_NO_SOURCE')\n    }\n\n    // @ts-ignore\n    if (destination == null) {\n      throw errCode(new Error('could not create destination'), 'ERR_NO_DESTINATION')\n    }\n\n    if (!options.create && !destination.exists) {\n      throw errCode(new Error('file does not exist'), 'ERR_NO_EXIST')\n    }\n\n    if (destination.entryType !== 'file') {\n      throw errCode(new Error('not a file'), 'ERR_NOT_A_FILE')\n    }\n\n    return updateOrImport(context, path, source, destination, options)\n  }\n\n  return withTimeoutOption(mfsWrite)\n}\n\n/**\n * @param {MfsContext} context\n * @param {string} path\n * @param {AsyncIterable<Uint8Array>} source\n * @param {FilePath} destination\n * @param {DefaultOptions} options\n */\nconst updateOrImport = async (context, path, source, destination, options) => {\n  const child = await write(context, source, destination, options)\n\n  // The slow bit is done, now add or replace the DAGLink in the containing directory\n  // re-reading the path to the containing folder in case it has changed in the interim\n  await createLock().writeLock(async () => {\n    const pathComponents = toPathComponents(path)\n    const fileName = pathComponents.pop()\n\n    if (fileName == null) {\n      throw errCode(new Error('source does not exist'), 'ERR_NO_EXIST')\n    }\n\n    let parentExists = false\n\n    try {\n      await stat(context)(`/${pathComponents.join('/')}`, options)\n      parentExists = true\n    } catch (err) {\n      if (err.code !== 'ERR_NOT_FOUND') {\n        throw err\n      }\n    }\n\n    if (!parentExists) {\n      await mkdir(context)(`/${pathComponents.join('/')}`, options)\n    }\n\n    // get an updated mfs path in case the root changed while we were writing\n    const updatedPath = await toMfsPath(context, path, options)\n    const trail = await toTrail(context, updatedPath.mfsDirectory)\n    const parent = trail[trail.length - 1]\n\n    if (!parent) {\n      throw errCode(new Error('directory does not exist'), 'ERR_NO_EXIST')\n    }\n\n    if (!parent.type || !parent.type.includes('directory')) {\n      throw errCode(new Error(`cannot write to ${parent.name}: Not a directory`), 'ERR_NOT_A_DIRECTORY')\n    }\n\n    const parentBlock = await context.repo.blocks.get(parent.cid)\n    const parentNode = decode(parentBlock)\n\n    const result = await addLink(context, {\n      parent: parentNode,\n      name: fileName,\n      cid: child.cid,\n      size: child.size,\n      flush: options.flush,\n      shardSplitThreshold: options.shardSplitThreshold,\n      hashAlg: options.hashAlg,\n      cidVersion: options.cidVersion\n    })\n\n    parent.cid = result.cid\n\n    // update the tree with the new child\n    const newRootCid = await updateTree(context, trail, options)\n\n    // Update the MFS record with the new CID for the root of the tree\n    await updateMfsRoot(context, newRootCid, options)\n  })()\n}\n\n/**\n * @param {MfsContext} context\n * @param {AsyncIterable<Uint8Array>} source\n * @param {FilePath} destination\n * @param {DefaultOptions} options\n */\nconst write = async (context, source, destination, options) => {\n  if (destination.exists) {\n    log(`Overwriting file ${destination.cid} offset ${options.offset} length ${options.length}`)\n  } else {\n    log(`Writing file offset ${options.offset} length ${options.length}`)\n  }\n\n  /** @type {Array<() => AsyncIterable<Uint8Array>>} */\n  const sources = []\n\n  // pad start of file if necessary\n  if (options.offset > 0) {\n    if (destination.unixfs) {\n      log(`Writing first ${options.offset} bytes of original file`)\n\n      sources.push(\n        () => {\n          return destination.content({\n            offset: 0,\n            length: options.offset\n          })\n        }\n      )\n\n      if (destination.unixfs.fileSize() < options.offset) {\n        const extra = options.offset - destination.unixfs.fileSize()\n\n        log(`Writing zeros for extra ${extra} bytes`)\n        sources.push(\n          asyncZeroes(extra)\n        )\n      }\n    } else {\n      log(`Writing zeros for first ${options.offset} bytes`)\n      sources.push(\n        asyncZeroes(options.offset)\n      )\n    }\n  }\n\n  sources.push(\n    limitAsyncStreamBytes(source, options.length)\n  )\n\n  const content = countBytesStreamed(catAsyncIterators(sources), (bytesWritten) => {\n    if (destination.unixfs && !options.truncate) {\n      // if we've done reading from the new source and we are not going\n      // to truncate the file, add the end of the existing file to the output\n      const fileSize = destination.unixfs.fileSize()\n\n      if (fileSize > bytesWritten) {\n        log(`Writing last ${fileSize - bytesWritten} of ${fileSize} bytes from original file starting at offset ${bytesWritten}`)\n\n        return destination.content({\n          offset: bytesWritten\n        })\n      } else {\n        log('Not writing last bytes from original file')\n      }\n    }\n\n    return {\n      [Symbol.asyncIterator]: async function * () {}\n    }\n  })\n\n  /** @type {number | undefined} */\n  let mode\n\n  if (options.mode !== undefined && options.mode !== null) {\n    mode = parseMode(options.mode)\n  } else if (destination && destination.unixfs) {\n    mode = destination.unixfs.mode\n  }\n\n  /** @type {import('ipfs-unixfs').Mtime | undefined} */\n  let mtime\n\n  if (options.mtime != null) {\n    mtime = parseMtime(options.mtime)\n  } else if (destination && destination.unixfs) {\n    mtime = destination.unixfs.mtime\n  }\n\n  let hasher\n  switch (options.hashAlg) {\n    case 'sha2-256':\n      hasher = sha256\n      break\n    case 'sha2-512':\n      hasher = sha512\n      break\n    default:\n      throw new Error(`TODO vmx 2021-03-31: Proper error message for unsupported hash algorithms like ${options.hashAlg}`)\n  }\n\n  const result = await last(importer([{\n    content: content,\n\n    // persist mode & mtime if set previously\n    mode,\n    mtime\n  }], context.repo.blocks, {\n    progress: options.progress,\n    hasher,\n    cidVersion: options.cidVersion,\n    strategy: options.strategy,\n    rawLeaves: options.rawLeaves,\n    reduceSingleLeafToSelf: options.reduceSingleLeafToSelf,\n    leafType: options.leafType\n  }))\n\n  if (!result) {\n    throw errCode(new Error(`cannot write to ${parent.name}`), 'ERR_COULD_NOT_WRITE')\n  }\n\n  log(`Wrote ${result.cid}`)\n\n  return {\n    cid: result.cid,\n    size: result.size\n  }\n}\n\n/**\n * @param {AsyncIterable<Uint8Array>} stream\n * @param {number} limit\n */\nconst limitAsyncStreamBytes = (stream, limit) => {\n  return async function * _limitAsyncStreamBytes () {\n    let emitted = 0\n\n    for await (const buf of stream) {\n      emitted += buf.length\n\n      if (emitted > limit) {\n        yield buf.slice(0, limit - emitted)\n\n        return\n      }\n\n      yield buf\n    }\n  }\n}\n\n/**\n * @param {number} count\n * @param {number} chunkSize\n */\nconst asyncZeroes = (count, chunkSize = MFS_MAX_CHUNK_SIZE) => {\n  const buf = new Uint8Array(chunkSize)\n\n  async function * _asyncZeroes () {\n    while (true) {\n      yield buf.slice()\n    }\n  }\n\n  return limitAsyncStreamBytes(_asyncZeroes(), count)\n}\n\n/**\n * @param {Array<() => AsyncIterable<Uint8Array>>} sources\n */\nconst catAsyncIterators = async function * (sources) { // eslint-disable-line require-await\n  for (let i = 0; i < sources.length; i++) {\n    yield * sources[i]()\n  }\n}\n\n/**\n * @param {AsyncIterable<Uint8Array>} source\n * @param {(count: number) => AsyncIterable<Uint8Array>} notify\n */\nconst countBytesStreamed = async function * (source, notify) {\n  let wrote = 0\n\n  for await (const buf of source) {\n    wrote += buf.length\n\n    yield buf\n  }\n\n  for await (const buf of notify(wrote)) {\n    wrote += buf.length\n\n    yield buf\n  }\n}\n"]},"metadata":{},"sourceType":"script"}