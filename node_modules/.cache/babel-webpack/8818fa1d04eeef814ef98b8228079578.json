{"ast":null,"code":"import _awaitAsyncGenerator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/awaitAsyncGenerator\";\nimport _wrapAsyncGenerator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/wrapAsyncGenerator\";\nimport _asyncIterator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/asyncIterator\";\nimport extractDataFromBlock from '../../../utils/extract-data-from-block.js';\nimport validateOffsetAndLength from '../../../utils/validate-offset-and-length.js';\nimport { UnixFS } from 'ipfs-unixfs';\nimport errCode from 'err-code';\nimport * as dagPb from '@ipld/dag-pb';\nimport * as dagCbor from '@ipld/dag-cbor';\nimport * as raw from 'multiformats/codecs/raw';\n\nfunction emitBytes(_x, _x2, _x3, _x4) {\n  return _emitBytes.apply(this, arguments);\n}\n\nfunction _emitBytes() {\n  _emitBytes = _wrapAsyncGenerator(function* (blockstore, node, start, end, streamPosition = 0, options) {\n    if (node instanceof Uint8Array) {\n      const buf = extractDataFromBlock(node, streamPosition, start, end);\n\n      if (buf.length) {\n        yield buf;\n      }\n\n      streamPosition += buf.length;\n      return streamPosition;\n    }\n\n    if (node.Data == null) {\n      throw errCode(new Error('no data in PBNode'), 'ERR_NOT_UNIXFS');\n    }\n\n    let file;\n\n    try {\n      file = UnixFS.unmarshal(node.Data);\n    } catch (err) {\n      throw errCode(err, 'ERR_NOT_UNIXFS');\n    }\n\n    if (file.data && file.data.length) {\n      const buf = extractDataFromBlock(file.data, streamPosition, start, end);\n\n      if (buf.length) {\n        yield buf;\n      }\n\n      streamPosition += file.data.length;\n    }\n\n    let childStart = streamPosition;\n\n    for (let i = 0; i < node.Links.length; i++) {\n      const childLink = node.Links[i];\n      const childEnd = streamPosition + file.blockSizes[i];\n\n      if (start >= childStart && start < childEnd || end > childStart && end <= childEnd || start < childStart && end > childEnd) {\n        const block = yield _awaitAsyncGenerator(blockstore.get(childLink.Hash, {\n          signal: options.signal\n        }));\n        let child;\n\n        switch (childLink.Hash.code) {\n          case dagPb.code:\n            child = yield _awaitAsyncGenerator(dagPb.decode(block));\n            break;\n\n          case raw.code:\n            child = block;\n            break;\n\n          case dagCbor.code:\n            child = yield _awaitAsyncGenerator(dagCbor.decode(block));\n            break;\n\n          default:\n            throw Error(`Unsupported codec: ${childLink.Hash.code}`);\n        }\n\n        var _iteratorNormalCompletion = true;\n        var _didIteratorError = false;\n\n        var _iteratorError;\n\n        try {\n          for (var _iterator = _asyncIterator(emitBytes(blockstore, child, start, end, streamPosition, options)), _step, _value; _step = yield _awaitAsyncGenerator(_iterator.next()), _iteratorNormalCompletion = _step.done, _value = yield _awaitAsyncGenerator(_step.value), !_iteratorNormalCompletion; _iteratorNormalCompletion = true) {\n            const buf = _value;\n            streamPosition += buf.length;\n            yield buf;\n          }\n        } catch (err) {\n          _didIteratorError = true;\n          _iteratorError = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion && _iterator.return != null) {\n              yield _awaitAsyncGenerator(_iterator.return());\n            }\n          } finally {\n            if (_didIteratorError) {\n              throw _iteratorError;\n            }\n          }\n        }\n      }\n\n      streamPosition = childEnd;\n      childStart = childEnd + 1;\n    }\n  });\n  return _emitBytes.apply(this, arguments);\n}\n\nconst fileContent = (cid, node, unixfs, path, resolve, depth, blockstore) => {\n  function yieldFileContent(options = {}) {\n    const fileSize = unixfs.fileSize();\n\n    if (fileSize === undefined) {\n      throw new Error('File was a directory');\n    }\n\n    const {\n      offset,\n      length\n    } = validateOffsetAndLength(fileSize, options.offset, options.length);\n    const start = offset;\n    const end = offset + length;\n    return emitBytes(blockstore, node, start, end, 0, options);\n  }\n\n  return yieldFileContent;\n};\n\nexport default fileContent;","map":null,"metadata":{},"sourceType":"module"}