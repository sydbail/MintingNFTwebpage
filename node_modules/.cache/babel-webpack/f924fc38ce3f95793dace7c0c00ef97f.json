{"ast":null,"code":"'use strict';\n\nvar _asyncToGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncToGenerator\").default;\n\nvar _wrapAsyncGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/wrapAsyncGenerator\").default;\n\nvar _awaitAsyncGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/awaitAsyncGenerator\").default;\n\nvar _asyncIterator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncIterator\").default;\n\nvar _asyncGeneratorDelegate = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncGeneratorDelegate\").default;\n\nconst {\n  CID\n} = require('multiformats/cid');\n\nconst {\n  ipfs: {\n    pin: {\n      Set: PinSet\n    }\n  }\n} = require('./pin'); // @ts-ignore\n\n\nconst fnv1a = require('fnv1a');\n\nconst varint = require('varint');\n\nconst dagPb = require('@ipld/dag-pb');\n\nconst {\n  DEFAULT_FANOUT,\n  MAX_ITEMS,\n  EMPTY_KEY\n} = require('./utils');\n\nconst {\n  concat: uint8ArrayConcat\n} = require('uint8arrays/concat');\n\nconst {\n  compare: uint8ArrayCompare\n} = require('uint8arrays/compare');\n\nconst {\n  toString: uint8ArrayToString\n} = require('uint8arrays/to-string');\n\nconst {\n  fromString: uint8ArrayFromString\n} = require('uint8arrays/from-string');\n\nconst {\n  sha256\n} = require('multiformats/hashes/sha2');\n/**\n * @typedef {import('interface-datastore').Datastore} Datastore\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n *\n * @typedef {object} Pin\n * @property {CID} key\n * @property {Uint8Array} [data]\n */\n\n/**\n * @param {PBNode} rootNode\n */\n\n\nfunction readHeader(rootNode) {\n  // rootNode.data should be a buffer of the format:\n  // < varint(headerLength) | header | itemData... >\n  const rootData = rootNode.Data;\n\n  if (!rootData) {\n    throw new Error('No data present');\n  }\n\n  const hdrLength = varint.decode(rootData);\n  const vBytes = varint.decode.bytes;\n\n  if (vBytes <= 0) {\n    throw new Error('Invalid Set header length');\n  }\n\n  if (vBytes + hdrLength > rootData.length) {\n    throw new Error('Impossibly large set header length');\n  }\n\n  const hdrSlice = rootData.slice(vBytes, hdrLength + vBytes);\n  const header = PinSet.toObject(PinSet.decode(hdrSlice), {\n    defaults: false,\n    arrays: true,\n    longs: Number,\n    objects: false\n  });\n\n  if (header.version !== 1) {\n    throw new Error(`Unsupported Set version: ${header.version}`);\n  }\n\n  if (header.fanout > rootNode.Links.length) {\n    throw new Error('Impossibly large fanout');\n  }\n\n  return {\n    header: header,\n    data: rootData.slice(hdrLength + vBytes)\n  };\n}\n/**\n * @param {number} seed\n * @param {CID} key\n */\n\n\nfunction hash(seed, key) {\n  const buffer = new Uint8Array(4);\n  const dataView = new DataView(buffer.buffer);\n  dataView.setUint32(0, seed, true);\n  const encodedKey = uint8ArrayFromString(key.toString());\n  const data = uint8ArrayConcat([buffer, encodedKey], buffer.byteLength + encodedKey.byteLength);\n  return fnv1a(uint8ArrayToString(data));\n}\n/**\n * @param {Blockstore} blockstore\n * @param {PBNode} node\n * @returns {AsyncGenerator<CID, void, undefined>}\n */\n\n\nfunction walkItems(_x, _x2) {\n  return _walkItems.apply(this, arguments);\n}\n/**\n * @param {Blockstore} blockstore\n * @param {PBNode} rootNode\n * @param {string} name\n */\n\n\nfunction _walkItems() {\n  _walkItems = _wrapAsyncGenerator(function* (blockstore, node) {\n    const pbh = readHeader(node);\n    let idx = 0;\n\n    for (const link of node.Links) {\n      if (idx < pbh.header.fanout) {\n        // the first pbh.header.fanout links are fanout bins\n        // if a fanout bin is not 'empty', dig into and walk its DAGLinks\n        const linkHash = link.Hash;\n\n        if (!EMPTY_KEY.equals(linkHash)) {\n          // walk the links of this fanout bin\n          const buf = yield _awaitAsyncGenerator(blockstore.get(linkHash));\n          const node = dagPb.decode(buf);\n          yield* _asyncGeneratorDelegate(_asyncIterator(walkItems(blockstore, node)), _awaitAsyncGenerator);\n        }\n      } else {\n        // otherwise, the link is a pin\n        yield link.Hash;\n      }\n\n      idx++;\n    }\n  });\n  return _walkItems.apply(this, arguments);\n}\n\nfunction loadSet(_x3, _x4, _x5) {\n  return _loadSet.apply(this, arguments);\n}\n/**\n * @param {Blockstore} blockstore\n * @param {Pin[]} items\n */\n\n\nfunction _loadSet() {\n  _loadSet = _wrapAsyncGenerator(function* (blockstore, rootNode, name) {\n    const link = rootNode.Links.find(l => l.Name === name);\n\n    if (!link) {\n      throw new Error('No link found with name ' + name);\n    }\n\n    const buf = yield _awaitAsyncGenerator(blockstore.get(link.Hash));\n    const node = dagPb.decode(buf);\n    yield* _asyncGeneratorDelegate(_asyncIterator(walkItems(blockstore, node)), _awaitAsyncGenerator);\n  });\n  return _loadSet.apply(this, arguments);\n}\n\nfunction storeItems(blockstore, items) {\n  return storePins(items, 0);\n  /**\n   * @param {Pin[]} pins\n   * @param {number} depth\n   */\n\n  function storePins(_x6, _x7) {\n    return _storePins.apply(this, arguments);\n  }\n\n  function _storePins() {\n    _storePins = _asyncToGenerator(function* (pins, depth) {\n      const pbHeader = PinSet.encode({\n        version: 1,\n        fanout: DEFAULT_FANOUT,\n        seed: depth\n      }).finish();\n      const header = varint.encode(pbHeader.length);\n      const headerBuf = uint8ArrayConcat([header, pbHeader]);\n      const fanoutLinks = [];\n\n      for (let i = 0; i < DEFAULT_FANOUT; i++) {\n        fanoutLinks.push({\n          Name: '',\n          Tsize: 1,\n          Hash: EMPTY_KEY\n        });\n      }\n\n      if (pins.length <= MAX_ITEMS) {\n        const nodes = pins.map(item => {\n          return {\n            link: {\n              Name: '',\n              Tsize: 1,\n              Hash: item.key\n            },\n            data: item.data || new Uint8Array()\n          };\n        }) // sorting makes any ordering of `pins` produce the same DAGNode\n        .sort((a, b) => {\n          return uint8ArrayCompare(a.link.Hash.bytes, b.link.Hash.bytes);\n        });\n        const rootLinks = fanoutLinks.concat(nodes.map(item => item.link));\n        const rootData = uint8ArrayConcat([headerBuf, ...nodes.map(item => item.data)]);\n        return {\n          Data: rootData,\n          Links: rootLinks\n        };\n      } else {\n        // If the array of pins is > MAX_ITEMS, we:\n        //  - distribute the pins among `DEFAULT_FANOUT` bins\n        //    - create a DAGNode for each bin\n        //      - add each pin as a DAGLink to that bin\n        //  - create a root DAGNode\n        //    - add each bin as a DAGLink\n        //  - send that root DAGNode via callback\n        // (using go-ipfs' \"wasteful but simple\" approach for consistency)\n        // https://github.com/ipfs/go-ipfs/blob/master/pin/set.go#L57\n\n        /** @type {Pin[][]} */\n        const bins = pins.reduce((bins, pin) => {\n          const n = hash(depth, pin.key) % DEFAULT_FANOUT; // @ts-ignore\n\n          bins[n] = n in bins ? bins[n].concat([pin]) : [pin];\n          return bins;\n        }, []);\n        let idx = 0;\n\n        for (const bin of bins) {\n          const child = yield storePins(bin, depth + 1);\n          yield storeChild(child, idx);\n          idx++;\n        }\n\n        return {\n          Data: headerBuf,\n          Links: fanoutLinks\n        };\n      }\n      /**\n       * @param {PBNode} child\n       * @param {number} binIdx\n       */\n\n\n      function storeChild(_x8, _x9) {\n        return _storeChild.apply(this, arguments);\n      }\n\n      function _storeChild() {\n        _storeChild = _asyncToGenerator(function* (child, binIdx) {\n          const buf = dagPb.encode(child);\n          const digest = yield sha256.digest(buf);\n          const cid = CID.createV0(digest);\n          yield blockstore.put(cid, buf);\n          const size = child.Links.reduce((acc, curr) => acc + (curr.Tsize || 0), 0) + buf.length;\n          fanoutLinks[binIdx] = {\n            Name: '',\n            Tsize: size,\n            Hash: cid\n          };\n        });\n        return _storeChild.apply(this, arguments);\n      }\n    });\n    return _storePins.apply(this, arguments);\n  }\n}\n/**\n * @param {Blockstore} blockstore\n * @param {string} type\n * @param {CID[]} cids\n */\n\n\nfunction storeSet(_x10, _x11, _x12) {\n  return _storeSet.apply(this, arguments);\n}\n\nfunction _storeSet() {\n  _storeSet = _asyncToGenerator(function* (blockstore, type, cids) {\n    const rootNode = yield storeItems(blockstore, cids.map(cid => {\n      return {\n        key: cid\n      };\n    }));\n    const buf = dagPb.encode(rootNode);\n    const digest = yield sha256.digest(buf);\n    const cid = CID.createV0(digest);\n    yield blockstore.put(cid, buf);\n    const size = rootNode.Links.reduce((acc, curr) => acc + curr.Tsize, 0) + buf.length;\n    return {\n      Name: type,\n      Tsize: size,\n      Hash: cid\n    };\n  });\n  return _storeSet.apply(this, arguments);\n}\n\nmodule.exports = {\n  loadSet,\n  storeSet\n};","map":null,"metadata":{},"sourceType":"script"}