{"ast":null,"code":"'use strict';\n\nvar _asyncToGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncToGenerator\").default;\n\nvar _awaitAsyncGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/awaitAsyncGenerator\").default;\n\nvar _wrapAsyncGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/wrapAsyncGenerator\").default;\n\nvar _asyncIterator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncIterator\").default;\n\nconst mergeOptions = require('merge-options').bind({\n  ignoreUndefined: true\n});\n\nconst toMfsPath = require('./utils/to-mfs-path');\n\nconst log = require('debug')('ipfs:mfs:touch');\n\nconst errCode = require('err-code');\n\nconst {\n  UnixFS\n} = require('ipfs-unixfs');\n\nconst toTrail = require('./utils/to-trail');\n\nconst addLink = require('./utils/add-link');\n\nconst updateTree = require('./utils/update-tree');\n\nconst updateMfsRoot = require('./utils/update-mfs-root');\n\nconst dagPb = require('@ipld/dag-pb');\n\nconst {\n  CID\n} = require('multiformats/cid');\n\nconst {\n  pipe\n} = require('it-pipe');\n\nconst {\n  importer\n} = require('ipfs-unixfs-importer');\n\nconst {\n  recursive\n} = require('ipfs-unixfs-exporter');\n\nconst last = require('it-last');\n\nconst cp = require('./cp');\n\nconst rm = require('./rm');\n\nconst persist = require('./utils/persist');\n\nconst withTimeoutOption = require('ipfs-core-utils/src/with-timeout-option');\n/**\n * @typedef {import('multiformats/cid').CIDVersion} CIDVersion\n * @typedef {import('@ipld/dag-pb').PBNode} PBNode\n * @typedef {import('./').MfsContext} MfsContext\n *\n * @typedef {object} DefaultOptions\n * @property {boolean} flush\n * @property {string} hashAlg\n * @property {CIDVersion} cidVersion\n * @property {number} shardSplitThreshold\n * @property {boolean} recursive\n * @property {AbortSignal} [signal]\n * @property {number} [timeout]\n */\n\n/**\n * @type {DefaultOptions}\n */\n\n\nconst defaultOptions = {\n  flush: true,\n  shardSplitThreshold: 1000,\n  hashAlg: 'sha2-256',\n  cidVersion: 0,\n  recursive: false\n};\n/**\n * @param {string} mode\n * @param {number} originalMode\n * @param {boolean} isDirectory\n */\n\nfunction calculateModification(mode, originalMode, isDirectory) {\n  let modification = 0;\n\n  if (mode.includes('x') || mode.includes('X') && (isDirectory || originalMode & 0o1 || originalMode & 0o10 || originalMode & 0o100)) {\n    modification += 1;\n  }\n\n  if (mode.includes('w')) {\n    modification += 2;\n  }\n\n  if (mode.includes('r')) {\n    modification += 4;\n  }\n\n  return modification;\n}\n/**\n * @param {string} references\n * @param {number} modification\n */\n\n\nfunction calculateUGO(references, modification) {\n  let ugo = 0;\n\n  if (references.includes('u')) {\n    ugo += modification << 6;\n  }\n\n  if (references.includes('g')) {\n    ugo += modification << 3;\n  }\n\n  if (references.includes('o')) {\n    ugo += modification;\n  }\n\n  return ugo;\n}\n/**\n * @param {string} references\n * @param {string} mode\n * @param {number} modification\n */\n\n\nfunction calculateSpecial(references, mode, modification) {\n  if (mode.includes('t')) {\n    modification += parseInt('1000', 8);\n  }\n\n  if (mode.includes('s')) {\n    if (references.includes('u')) {\n      modification += parseInt('4000', 8);\n    }\n\n    if (references.includes('g')) {\n      modification += parseInt('2000', 8);\n    }\n  }\n\n  return modification;\n}\n/**\n * https://en.wikipedia.org/wiki/Chmod#Symbolic_modes\n *\n * @param {string} input\n * @param {number} originalMode\n * @param {boolean} isDirectory\n */\n\n\nfunction parseSymbolicMode(input, originalMode, isDirectory) {\n  if (!originalMode) {\n    originalMode = 0;\n  }\n\n  const match = input.match(/^(u?g?o?a?)(-?\\+?=?)?(r?w?x?X?s?t?)$/);\n\n  if (!match) {\n    throw new Error(`Invalid file mode: ${input}`);\n  }\n\n  let [, references, operator, mode] = match;\n\n  if (references === 'a' || !references) {\n    references = 'ugo';\n  }\n\n  let modification = calculateModification(mode, originalMode, isDirectory);\n  modification = calculateUGO(references, modification);\n  modification = calculateSpecial(references, mode, modification);\n\n  if (operator === '=') {\n    if (references.includes('u')) {\n      // blank u bits\n      originalMode = originalMode & parseInt('7077', 8); // or them together\n\n      originalMode = originalMode | modification;\n    }\n\n    if (references.includes('g')) {\n      // blank g bits\n      originalMode = originalMode & parseInt('7707', 8); // or them together\n\n      originalMode = originalMode | modification;\n    }\n\n    if (references.includes('o')) {\n      // blank o bits\n      originalMode = originalMode & parseInt('7770', 8); // or them together\n\n      originalMode = originalMode | modification;\n    }\n\n    return originalMode;\n  }\n\n  if (operator === '+') {\n    return modification | originalMode;\n  }\n\n  if (operator === '-') {\n    return modification ^ originalMode;\n  }\n\n  return originalMode;\n}\n/**\n * @param {string | InstanceType<typeof window.String> | number} mode\n * @param {UnixFS} metadata\n * @returns {number}\n */\n\n\nfunction calculateMode(mode, metadata) {\n  if (mode instanceof String || typeof mode === 'string') {\n    const strMode = `${mode}`;\n\n    if (strMode.match(/^\\d+$/g)) {\n      mode = parseInt(strMode, 8);\n    } else {\n      // @ts-ignore freaks out over the curr: number, acc: string thing\n      mode = 0 + strMode.split(',').reduce((curr, acc) => {\n        return parseSymbolicMode(acc, curr, metadata.isDirectory());\n      }, metadata.mode || 0);\n    }\n  }\n\n  return mode;\n}\n/**\n * @param {MfsContext} context\n */\n\n\nmodule.exports = context => {\n  /**\n   * @type {import('ipfs-core-types/src/files').API[\"chmod\"]}\n   */\n  function mfsChmod(_x4, _x5) {\n    return _mfsChmod.apply(this, arguments);\n  }\n\n  function _mfsChmod() {\n    _mfsChmod = _asyncToGenerator(function* (path, mode, options = {}) {\n      /** @type {DefaultOptions} */\n      const opts = mergeOptions(defaultOptions, options);\n      log(`Fetching stats for ${path}`);\n      const {\n        cid,\n        mfsDirectory,\n        name\n      } = yield toMfsPath(context, path, opts);\n\n      if (cid.code !== dagPb.code) {\n        throw errCode(new Error(`${path} was not a UnixFS node`), 'ERR_NOT_UNIXFS');\n      }\n\n      if (opts.recursive) {\n        // recursively export from root CID, change perms of each entry then reimport\n        // but do not reimport files, only manipulate dag-pb nodes\n        const root = yield pipe( /*#__PURE__*/_wrapAsyncGenerator(function* () {\n          var _iteratorNormalCompletion = true;\n          var _didIteratorError = false;\n\n          var _iteratorError;\n\n          try {\n            for (var _iterator = _asyncIterator(recursive(cid, context.repo.blocks)), _step, _value; _step = yield _awaitAsyncGenerator(_iterator.next()), _iteratorNormalCompletion = _step.done, _value = yield _awaitAsyncGenerator(_step.value), !_iteratorNormalCompletion; _iteratorNormalCompletion = true) {\n              const entry = _value;\n\n              if (entry.type !== 'file' && entry.type !== 'directory') {\n                throw errCode(new Error(`${path} was not a UnixFS node`), 'ERR_NOT_UNIXFS');\n              }\n\n              entry.unixfs.mode = calculateMode(mode, entry.unixfs);\n              const node = dagPb.prepare({\n                Data: entry.unixfs.marshal(),\n                Links: entry.node.Links\n              });\n              yield {\n                path: entry.path,\n                content: node\n              };\n            }\n          } catch (err) {\n            _didIteratorError = true;\n            _iteratorError = err;\n          } finally {\n            try {\n              if (!_iteratorNormalCompletion && _iterator.return != null) {\n                yield _awaitAsyncGenerator(_iterator.return());\n              }\n            } finally {\n              if (_didIteratorError) {\n                throw _iteratorError;\n              }\n            }\n          }\n        }), // @ts-ignore we account for the incompatible source type with our custom dag builder below\n        source => importer(source, context.repo.blocks, { ...opts,\n          pin: false,\n          dagBuilder: function () {\n            var _ref2 = _wrapAsyncGenerator(function* (source, block, opts) {\n              var _iteratorNormalCompletion2 = true;\n              var _didIteratorError2 = false;\n\n              var _iteratorError2;\n\n              try {\n                for (var _iterator2 = _asyncIterator(source), _step2, _value2; _step2 = yield _awaitAsyncGenerator(_iterator2.next()), _iteratorNormalCompletion2 = _step2.done, _value2 = yield _awaitAsyncGenerator(_step2.value), !_iteratorNormalCompletion2; _iteratorNormalCompletion2 = true) {\n                  const entry = _value2;\n                  yield /*#__PURE__*/_asyncToGenerator(function* () {\n                    /** @type {PBNode} */\n                    // @ts-ignore - cannot derive type\n                    const node = entry.content;\n                    const buf = dagPb.encode(node);\n                    const cid = yield persist(buf, block, opts);\n\n                    if (!node.Data) {\n                      throw errCode(new Error(`${cid} had no data`), 'ERR_INVALID_NODE');\n                    }\n\n                    const unixfs = UnixFS.unmarshal(node.Data);\n                    return {\n                      cid,\n                      size: buf.length,\n                      path: entry.path,\n                      unixfs\n                    };\n                  });\n                }\n              } catch (err) {\n                _didIteratorError2 = true;\n                _iteratorError2 = err;\n              } finally {\n                try {\n                  if (!_iteratorNormalCompletion2 && _iterator2.return != null) {\n                    yield _awaitAsyncGenerator(_iterator2.return());\n                  }\n                } finally {\n                  if (_didIteratorError2) {\n                    throw _iteratorError2;\n                  }\n                }\n              }\n            });\n\n            return function dagBuilder(_x, _x2, _x3) {\n              return _ref2.apply(this, arguments);\n            };\n          }()\n        }), nodes => last(nodes));\n\n        if (!root) {\n          throw errCode(new Error(`Could not chmod ${path}`), 'ERR_COULD_NOT_CHMOD');\n        } // remove old path from mfs\n\n\n        yield rm(context)(path, opts); // add newly created tree to mfs at path\n\n        yield cp(context)(`/ipfs/${root.cid}`, path, opts);\n        return;\n      }\n\n      const block = yield context.repo.blocks.get(cid);\n      const node = dagPb.decode(block);\n\n      if (!node.Data) {\n        throw errCode(new Error(`${cid} had no data`), 'ERR_INVALID_NODE');\n      }\n\n      const metadata = UnixFS.unmarshal(node.Data);\n      metadata.mode = calculateMode(mode, metadata);\n      const updatedBlock = dagPb.encode({\n        Data: metadata.marshal(),\n        Links: node.Links\n      });\n      const hashAlg = opts.hashAlg || defaultOptions.hashAlg;\n      const hasher = yield context.hashers.getHasher(hashAlg);\n      const hash = yield hasher.digest(updatedBlock);\n      const updatedCid = CID.create(opts.cidVersion, dagPb.code, hash);\n\n      if (opts.flush) {\n        yield context.repo.blocks.put(updatedCid, updatedBlock);\n      }\n\n      const trail = yield toTrail(context, mfsDirectory);\n      const parent = trail[trail.length - 1];\n      const parentCid = CID.decode(parent.cid.bytes);\n      const parentBlock = yield context.repo.blocks.get(parentCid);\n      const parentNode = dagPb.decode(parentBlock);\n      const result = yield addLink(context, {\n        parent: parentNode,\n        name: name,\n        cid: updatedCid,\n        size: updatedBlock.length,\n        flush: opts.flush,\n        // TODO vmx 2021-03-29: decide on the API, whether it should be a `hashAlg` or `hasher`\n        hashAlg,\n        cidVersion: cid.version,\n        shardSplitThreshold: Infinity\n      });\n      parent.cid = result.cid; // update the tree with the new child\n\n      const newRootCid = yield updateTree(context, trail, opts); // Update the MFS record with the new CID for the root of the tree\n\n      yield updateMfsRoot(context, newRootCid, opts);\n    });\n    return _mfsChmod.apply(this, arguments);\n  }\n\n  return withTimeoutOption(mfsChmod);\n};","map":null,"metadata":{},"sourceType":"script"}