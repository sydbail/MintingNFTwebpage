{"ast":null,"code":"import _asyncToGenerator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _awaitAsyncGenerator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/awaitAsyncGenerator\";\nimport _wrapAsyncGenerator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/wrapAsyncGenerator\";\nimport _asyncIterator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/asyncIterator\";\nimport errCode from 'err-code';\nimport { UnixFS } from 'ipfs-unixfs';\nimport persist from '../../utils/persist.js';\nimport { encode, prepare } from '@ipld/dag-pb';\nimport parallelBatch from 'it-parallel-batch';\nimport * as rawCodec from 'multiformats/codecs/raw';\nimport * as dagPb from '@ipld/dag-pb';\nimport dagFlat from './flat.js';\nimport dagBalanced from './balanced.js';\nimport dagTrickle from './trickle.js';\nconst dagBuilders = {\n  flat: dagFlat,\n  balanced: dagBalanced,\n  trickle: dagTrickle\n};\n\nfunction buildFileBatch(_x, _x2, _x3) {\n  return _buildFileBatch.apply(this, arguments);\n}\n\nfunction _buildFileBatch() {\n  _buildFileBatch = _wrapAsyncGenerator(function* (file, blockstore, options) {\n    let count = -1;\n    let previous;\n    let bufferImporter;\n\n    if (typeof options.bufferImporter === 'function') {\n      bufferImporter = options.bufferImporter;\n    } else {\n      bufferImporter = (yield _awaitAsyncGenerator(import('./buffer-importer.js'))).default;\n    }\n\n    var _iteratorNormalCompletion = true;\n    var _didIteratorError = false;\n\n    var _iteratorError;\n\n    try {\n      for (var _iterator = _asyncIterator(parallelBatch(bufferImporter(file, blockstore, options), options.blockWriteConcurrency)), _step, _value; _step = yield _awaitAsyncGenerator(_iterator.next()), _iteratorNormalCompletion = _step.done, _value = yield _awaitAsyncGenerator(_step.value), !_iteratorNormalCompletion; _iteratorNormalCompletion = true) {\n        const entry = _value;\n        count++;\n\n        if (count === 0) {\n          previous = entry;\n          continue;\n        } else if (count === 1 && previous) {\n          yield previous;\n          previous = null;\n        }\n\n        yield entry;\n      }\n    } catch (err) {\n      _didIteratorError = true;\n      _iteratorError = err;\n    } finally {\n      try {\n        if (!_iteratorNormalCompletion && _iterator.return != null) {\n          yield _awaitAsyncGenerator(_iterator.return());\n        }\n      } finally {\n        if (_didIteratorError) {\n          throw _iteratorError;\n        }\n      }\n    }\n\n    if (previous) {\n      previous.single = true;\n      yield previous;\n    }\n  });\n  return _buildFileBatch.apply(this, arguments);\n}\n\nconst reduce = (file, blockstore, options) => {\n  function reducer(_x4) {\n    return _reducer.apply(this, arguments);\n  }\n\n  function _reducer() {\n    _reducer = _asyncToGenerator(function* (leaves) {\n      if (leaves.length === 1 && leaves[0].single && options.reduceSingleLeafToSelf) {\n        const leaf = leaves[0];\n\n        if (leaf.cid.code === rawCodec.code && (file.mtime !== undefined || file.mode !== undefined)) {\n          let buffer = yield blockstore.get(leaf.cid);\n          leaf.unixfs = new UnixFS({\n            type: 'file',\n            mtime: file.mtime,\n            mode: file.mode,\n            data: buffer\n          });\n          buffer = encode(prepare({\n            Data: leaf.unixfs.marshal()\n          }));\n          leaf.cid = yield persist(buffer, blockstore, { ...options,\n            codec: dagPb,\n            hasher: options.hasher,\n            cidVersion: options.cidVersion\n          });\n          leaf.size = buffer.length;\n        }\n\n        return {\n          cid: leaf.cid,\n          path: file.path,\n          unixfs: leaf.unixfs,\n          size: leaf.size\n        };\n      }\n\n      const f = new UnixFS({\n        type: 'file',\n        mtime: file.mtime,\n        mode: file.mode\n      });\n      const links = leaves.filter(leaf => {\n        if (leaf.cid.code === rawCodec.code && leaf.size) {\n          return true;\n        }\n\n        if (leaf.unixfs && !leaf.unixfs.data && leaf.unixfs.fileSize()) {\n          return true;\n        }\n\n        return Boolean(leaf.unixfs && leaf.unixfs.data && leaf.unixfs.data.length);\n      }).map(leaf => {\n        if (leaf.cid.code === rawCodec.code) {\n          f.addBlockSize(leaf.size);\n          return {\n            Name: '',\n            Tsize: leaf.size,\n            Hash: leaf.cid\n          };\n        }\n\n        if (!leaf.unixfs || !leaf.unixfs.data) {\n          f.addBlockSize(leaf.unixfs && leaf.unixfs.fileSize() || 0);\n        } else {\n          f.addBlockSize(leaf.unixfs.data.length);\n        }\n\n        return {\n          Name: '',\n          Tsize: leaf.size,\n          Hash: leaf.cid\n        };\n      });\n      const node = {\n        Data: f.marshal(),\n        Links: links\n      };\n      const buffer = encode(prepare(node));\n      const cid = yield persist(buffer, blockstore, options);\n      return {\n        cid,\n        path: file.path,\n        unixfs: f,\n        size: buffer.length + node.Links.reduce((acc, curr) => acc + curr.Tsize, 0)\n      };\n    });\n    return _reducer.apply(this, arguments);\n  }\n\n  return reducer;\n};\n\nfunction fileBuilder(file, block, options) {\n  const dagBuilder = dagBuilders[options.strategy];\n\n  if (!dagBuilder) {\n    throw errCode(new Error(`Unknown importer build strategy name: ${options.strategy}`), 'ERR_BAD_STRATEGY');\n  }\n\n  return dagBuilder(buildFileBatch(file, block, options), reduce(file, block, options), options);\n}\n\nexport default fileBuilder;","map":null,"metadata":{},"sourceType":"module"}