{"ast":null,"code":"'use strict';\n\nvar _asyncToGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncToGenerator\").default;\n\nvar _asyncGeneratorDelegate = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncGeneratorDelegate\").default;\n\nvar _asyncIterator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncIterator\").default;\n\nvar _awaitAsyncGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/awaitAsyncGenerator\").default;\n\nvar _wrapAsyncGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/wrapAsyncGenerator\").default;\n\nconst {\n  encode,\n  prepare\n} = require('@ipld/dag-pb');\n\nconst {\n  UnixFS\n} = require('ipfs-unixfs');\n\nconst persist = require('./persist');\n\nconst {\n  createHAMT,\n  Bucket\n} = require('hamt-sharding');\n\nconst {\n  hamtHashCode,\n  hamtHashFn,\n  hamtBucketBits\n} = require('./hamt-constants');\n/**\n * @typedef {import('ipfs-unixfs-importer').ImporterOptions} ImporterOptions\n * @typedef {import('interface-blockstore').Blockstore} Blockstore\n * @typedef {import('multiformats/cid').CID} CID\n * @typedef {import('ipfs-unixfs').Mtime} Mtime\n *\n * @typedef {object} ImportResult\n * @property {CID} cid\n * @property {import('@ipld/dag-pb').PBNode} node\n * @property {number} size\n *\n * @typedef {object} DirContents\n * @property {CID} [cid]\n * @property {number} [size]\n *\n * @typedef {object} DirOptions\n * @property {Mtime} [mtime]\n * @property {number} [mode]\n * @property {import('multiformats/codecs/interface').BlockCodec<any, any>} [codec]\n * @property {import('multiformats/cid').CIDVersion} [cidVersion]\n * @property {boolean} [onlyHash]\n * @property {AbortSignal} [signal]\n */\n\n/**\n * @typedef {object} DirProps\n * @property {boolean} root\n * @property {boolean} dir\n * @property {string} path\n * @property {boolean} dirty\n * @property {boolean} flat\n * @property {Dir} [parent]\n * @property {string} [parentKey]\n * @property {import('ipfs-unixfs').UnixFS} [unixfs]\n * @property {number} [mode]\n * @property {import('ipfs-unixfs').Mtime} [mtime]\n */\n\n\nclass Dir {\n  /**\n   * @param {DirProps} props\n   * @param {DirOptions} options\n   */\n  constructor(props, options) {\n    this.options = options || {};\n    this.root = props.root;\n    this.dir = props.dir;\n    this.path = props.path;\n    this.dirty = props.dirty;\n    this.flat = props.flat;\n    this.parent = props.parent;\n    this.parentKey = props.parentKey;\n    this.unixfs = props.unixfs;\n    this.mode = props.mode;\n    this.mtime = props.mtime;\n    /** @type {CID | undefined} */\n\n    this.cid = undefined;\n    /** @type {number | undefined} */\n\n    this.size = undefined;\n  }\n  /**\n   * @param {string} name\n   * @param {DirContents} value\n   */\n\n\n  put(name, value) {\n    return _asyncToGenerator(function* () {})();\n  }\n  /**\n   * @param {string} name\n   * @returns {Promise<DirContents | undefined>}\n   */\n\n\n  get(name) {\n    return Promise.resolve(this);\n  }\n  /**\n   * @returns {AsyncIterable<{ key: string, child: DirContents}>}\n   */\n\n\n  eachChildSeries() {\n    return _wrapAsyncGenerator(function* () {})();\n  }\n  /**\n   * @param {Blockstore} blockstore\n   * @returns {AsyncIterable<ImportResult>}\n   */\n\n\n  flush(blockstore) {\n    return _wrapAsyncGenerator(function* () {})();\n  }\n\n}\n\nclass DirSharded extends Dir {\n  /**\n   * @param {DirProps} props\n   * @param {DirOptions} options\n   */\n  constructor(props, options) {\n    super(props, options);\n    /** @type {Bucket<DirContents>} */\n\n    this._bucket = createHAMT({\n      hashFn: hamtHashFn,\n      bits: hamtBucketBits\n    });\n  }\n  /**\n   * @param {string} name\n   * @param {DirContents} value\n   */\n\n\n  put(name, value) {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      yield _this3._bucket.put(name, value);\n    })();\n  }\n  /**\n   * @param {string} name\n   */\n\n\n  get(name) {\n    return this._bucket.get(name);\n  }\n\n  childCount() {\n    return this._bucket.leafCount();\n  }\n\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n\n  eachChildSeries() {\n    var _this = this;\n\n    return _wrapAsyncGenerator(function* () {\n      var _iteratorNormalCompletion = true;\n      var _didIteratorError = false;\n\n      var _iteratorError;\n\n      try {\n        for (var _iterator = _asyncIterator(_this._bucket.eachLeafSeries()), _step, _value; _step = yield _awaitAsyncGenerator(_iterator.next()), _iteratorNormalCompletion = _step.done, _value = yield _awaitAsyncGenerator(_step.value), !_iteratorNormalCompletion; _iteratorNormalCompletion = true) {\n          const {\n            key,\n            value\n          } = _value;\n          yield {\n            key,\n            child: value\n          };\n        }\n      } catch (err) {\n        _didIteratorError = true;\n        _iteratorError = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion && _iterator.return != null) {\n            yield _awaitAsyncGenerator(_iterator.return());\n          }\n        } finally {\n          if (_didIteratorError) {\n            throw _iteratorError;\n          }\n        }\n      }\n    })();\n  }\n  /**\n   * @param {Blockstore} blockstore\n   * @returns {AsyncIterable<ImportResult>}\n   */\n\n\n  flush(blockstore) {\n    var _this2 = this;\n\n    return _wrapAsyncGenerator(function* () {\n      yield* _asyncGeneratorDelegate(_asyncIterator(flush(_this2._bucket, blockstore, _this2, _this2.options)), _awaitAsyncGenerator);\n    })();\n  }\n\n}\n\nmodule.exports = DirSharded;\n/**\n * @param {Bucket<?>} bucket\n * @param {Blockstore} blockstore\n * @param {*} shardRoot\n * @param {DirOptions} options\n * @returns {AsyncIterable<ImportResult>}\n */\n\nfunction flush(_x, _x2, _x3, _x4) {\n  return _flush.apply(this, arguments);\n}\n\nfunction _flush() {\n  _flush = _wrapAsyncGenerator(function* (bucket, blockstore, shardRoot, options) {\n    const children = bucket._children;\n    const links = [];\n    let childrenSize = 0;\n\n    for (let i = 0; i < children.length; i++) {\n      const child = children.get(i);\n\n      if (!child) {\n        continue;\n      }\n\n      const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n\n      if (child instanceof Bucket) {\n        let shard;\n        var _iteratorNormalCompletion2 = true;\n        var _didIteratorError2 = false;\n\n        var _iteratorError2;\n\n        try {\n          for (var _iterator2 = _asyncIterator(yield _awaitAsyncGenerator(flush(child, blockstore, null, options))), _step2, _value2; _step2 = yield _awaitAsyncGenerator(_iterator2.next()), _iteratorNormalCompletion2 = _step2.done, _value2 = yield _awaitAsyncGenerator(_step2.value), !_iteratorNormalCompletion2; _iteratorNormalCompletion2 = true) {\n            const subShard = _value2;\n            shard = subShard;\n          }\n        } catch (err) {\n          _didIteratorError2 = true;\n          _iteratorError2 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion2 && _iterator2.return != null) {\n              yield _awaitAsyncGenerator(_iterator2.return());\n            }\n          } finally {\n            if (_didIteratorError2) {\n              throw _iteratorError2;\n            }\n          }\n        }\n\n        if (!shard) {\n          throw new Error('Could not flush sharded directory, no subshard found');\n        }\n\n        links.push({\n          Name: labelPrefix,\n          Tsize: shard.size,\n          Hash: shard.cid\n        });\n        childrenSize += shard.size;\n      } else if (typeof child.value.flush === 'function') {\n        const dir = child.value;\n        let flushedDir;\n        var _iteratorNormalCompletion3 = true;\n        var _didIteratorError3 = false;\n\n        var _iteratorError3;\n\n        try {\n          for (var _iterator3 = _asyncIterator(dir.flush(blockstore)), _step3, _value3; _step3 = yield _awaitAsyncGenerator(_iterator3.next()), _iteratorNormalCompletion3 = _step3.done, _value3 = yield _awaitAsyncGenerator(_step3.value), !_iteratorNormalCompletion3; _iteratorNormalCompletion3 = true) {\n            const entry = _value3;\n            flushedDir = entry;\n            yield flushedDir;\n          }\n        } catch (err) {\n          _didIteratorError3 = true;\n          _iteratorError3 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion3 && _iterator3.return != null) {\n              yield _awaitAsyncGenerator(_iterator3.return());\n            }\n          } finally {\n            if (_didIteratorError3) {\n              throw _iteratorError3;\n            }\n          }\n        }\n\n        const label = labelPrefix + child.key;\n        links.push({\n          Name: label,\n          Tsize: flushedDir.size,\n          Hash: flushedDir.cid\n        });\n        childrenSize += flushedDir.size;\n      } else {\n        const value = child.value;\n\n        if (!value.cid) {\n          continue;\n        }\n\n        const label = labelPrefix + child.key;\n        const size = value.size;\n        links.push({\n          Name: label,\n          Tsize: size,\n          Hash: value.cid\n        });\n        childrenSize += size;\n      }\n    } // go-ipfs uses little endian, that's why we have to\n    // reverse the bit field before storing it\n\n\n    const data = Uint8Array.from(children.bitField().reverse());\n    const dir = new UnixFS({\n      type: 'hamt-sharded-directory',\n      data,\n      fanout: bucket.tableSize(),\n      hashType: hamtHashCode,\n      mtime: shardRoot && shardRoot.mtime,\n      mode: shardRoot && shardRoot.mode\n    });\n    const node = {\n      Data: dir.marshal(),\n      Links: links\n    };\n    const buffer = encode(prepare(node));\n    const cid = yield _awaitAsyncGenerator(persist(buffer, blockstore, options));\n    const size = buffer.length + childrenSize;\n    yield {\n      cid,\n      node,\n      size\n    };\n  });\n  return _flush.apply(this, arguments);\n}","map":null,"metadata":{},"sourceType":"script"}