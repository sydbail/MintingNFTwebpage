{"ast":null,"code":"'use strict';\n\nvar _asyncToGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncToGenerator\").default;\n\nconst {\n  default: Queue\n} = require('p-queue');\n/**\n * @typedef {import('peer-id')} PeerId\n */\n\n\nclass WorkerQueue {\n  /**\n   * Creates a new WorkerQueue.\n   *\n   * @param {import('../index')} dht\n   * @param {import('./run')} run\n   * @param {import('./path')} path\n   * @param {Function & {error: Function}} log\n   */\n  constructor(dht, run, path, log) {\n    this.dht = dht;\n    this.run = run;\n    this.path = path;\n    this.log = log;\n    this.concurrency = this.dht.concurrency;\n    this.queue = this.setupQueue(); // a container for resolve/reject functions that will be populated\n    // when execute() is called\n\n    /** @type {{ resolve: (result?: any) => void, reject: (err: Error) => void} | null} */\n\n    this.execution = null;\n    /** @type {Set<PeerId>} */\n\n    this.queuedPeerIds = new Set();\n  }\n  /**\n   * Create the underlying async queue.\n   *\n   * @returns {Queue}\n   */\n\n\n  setupQueue() {\n    const q = new Queue({\n      concurrency: this.concurrency\n    }); // When all peers in the queue have been processed, stop the worker\n\n    q.on('idle', () => {\n      if (this.path.peersToQuery && !this.path.peersToQuery.length) {\n        this.log('queue:drain');\n        this.stop();\n      }\n    }); // When a space opens up in the queue, add some more peers\n\n    q.on('next', () => {\n      if (!this.running) {\n        return;\n      }\n\n      if (q.pending < this.concurrency) {\n        this.fill();\n      }\n    });\n    return q;\n  }\n  /**\n   * Stop the worker, optionally providing an error to pass to the worker's\n   * callback.\n   *\n   * @param {Error} [err]\n   */\n\n\n  stop(err) {\n    if (!this.running) {\n      return;\n    }\n\n    this.running = false;\n    this.queue.clear();\n    this.log('worker:stop, %d workers still running', this.run.workers.filter(w => w.running).length);\n\n    if (this.execution) {\n      if (err) {\n        this.execution.reject(err);\n      } else {\n        this.execution.resolve();\n      }\n    }\n  }\n  /**\n   * Use the queue from async to keep `concurrency` amount items running\n   * per path.\n   *\n   * @returns {Promise<void>}\n   */\n\n\n  execute() {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      _this.running = true; // store the promise resolution functions to be resolved at end of queue\n\n      _this.execution = null;\n      const execPromise = new Promise((resolve, reject) => {\n        _this.execution = {\n          resolve,\n          reject\n        };\n      }); // start queue\n\n      _this.fill(); // await completion\n\n\n      yield execPromise;\n    })();\n  }\n  /**\n   * Add peers to the worker queue until there are enough to satisfy the\n   * worker queue concurrency.\n   * Note that we don't want to take any more than those required to satisfy\n   * concurrency from the peers-to-query queue, because we always want to\n   * query the closest peers to the key first, and new peers are continuously\n   * being added to the peers-to-query queue.\n   */\n\n\n  fill() {\n    if (!this.path.peersToQuery) {\n      return;\n    } // Note:\n    // - queue.pending: number of items that are currently running\n    // - queue.size: the number of items that are waiting to be run\n\n\n    while (this.queue.pending + this.queue.size < this.concurrency && this.path.peersToQuery.length > 0) {\n      const peer = this.path.peersToQuery.dequeue(); // store the peer id so we can potentially abort early\n\n      this.queuedPeerIds.add(peer);\n      this.queue.add(() => {\n        return this.processNext(peer).catch(err => {\n          this.log.error('queue', err);\n          this.stop(err);\n        }).finally(() => {\n          this.queuedPeerIds.delete(peer);\n        });\n      });\n    }\n  }\n  /**\n   * Process the next peer in the queue\n   *\n   * @param {PeerId} peer\n   */\n\n\n  processNext(peer) {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      if (!_this2.running) {\n        return;\n      } // The paths must be disjoint, meaning that no two paths in the Query may\n      // traverse the same peer\n\n\n      if (_this2.run.peersSeen.has(peer.toB58String())) {\n        return;\n      } // Check if we've queried enough peers already\n\n\n      let continueQuerying, continueQueryingError;\n\n      try {\n        continueQuerying = yield _this2.run.continueQuerying(_this2);\n      } catch (err) {\n        continueQueryingError = err;\n      } // Abort and ignore any error if we're no longer running\n\n\n      if (!_this2.running) {\n        return;\n      }\n\n      if (continueQueryingError) {\n        throw continueQueryingError;\n      } // No peer we're querying is closer, stop the queue\n      // This will cause queries that may potentially result in\n      // closer nodes to be ended, but it reduces overall query time\n\n\n      if (!continueQuerying) {\n        _this2.stop();\n\n        return;\n      } // Check if another path has queried this peer in the mean time\n\n\n      if (_this2.run.peersSeen.has(peer.toB58String())) {\n        return;\n      }\n\n      _this2.run.peersSeen.add(peer.toB58String()); // Execute the query on the next peer\n\n\n      _this2.log('queue:work');\n\n      let state, execError;\n\n      try {\n        state = yield _this2.execQuery(peer);\n      } catch (err) {\n        execError = err;\n      } // Abort and ignore any error if we're no longer running\n\n\n      if (!_this2.running) {\n        return;\n      }\n\n      _this2.log('queue:work:done', execError, state);\n\n      if (execError) {\n        throw execError;\n      } // If query is complete, stop all workers.\n      // Note: run.stop() calls stop() on all the workers, which kills the\n      // queue and resolves execution\n\n\n      if (state && state.queryComplete) {\n        _this2.log('query:complete');\n\n        _this2.run.stop();\n\n        return;\n      } // If path is complete, just stop this worker.\n      // Note: this.stop() kills the queue and resolves execution\n\n\n      if (state && state.pathComplete) {\n        _this2.stop();\n      }\n    })();\n  }\n  /**\n   * Execute a query on the next peer.\n   *\n   * @param {PeerId} peer\n   */\n\n\n  execQuery(peer) {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      let res, queryError;\n\n      try {\n        res = yield _this3.path.queryFunc(peer);\n      } catch (err) {\n        queryError = err;\n      } // Abort and ignore any error if we're no longer running\n\n\n      if (!_this3.running) {\n        return;\n      }\n\n      if (queryError) {\n        _this3.run.errors.push(queryError);\n\n        return;\n      } // Add the peer to the closest peers we have successfully queried\n\n\n      _this3.run.peersQueried && (yield _this3.run.peersQueried.add(peer));\n\n      if (!res) {\n        return;\n      } // If the query indicates that this path or the whole query is complete\n      // set the path result and bail out\n\n\n      if (res.pathComplete || res.queryComplete) {\n        _this3.path.res = res;\n        return {\n          pathComplete: res.pathComplete,\n          queryComplete: res.queryComplete\n        };\n      } // If there are closer peers to query, add them to the queue\n\n\n      if (res.closerPeers && res.closerPeers.length > 0) {\n        /**\n         * @param {import('../').PeerData} closer\n         */\n        const queryCloser = /*#__PURE__*/function () {\n          var _ref = _asyncToGenerator(function* (closer) {\n            // don't add ourselves\n            if (_this3.dht._isSelf(closer.id)) {\n              return;\n            }\n\n            _this3.dht._peerDiscovered(closer.id, closer.multiaddrs);\n\n            yield _this3.path.addPeerToQuery(closer.id);\n          });\n\n          return function queryCloser(_x) {\n            return _ref.apply(this, arguments);\n          };\n        }();\n\n        yield Promise.all(res.closerPeers.map(queryCloser));\n      }\n    })();\n  }\n\n}\n\nmodule.exports = WorkerQueue;","map":null,"metadata":{},"sourceType":"script"}