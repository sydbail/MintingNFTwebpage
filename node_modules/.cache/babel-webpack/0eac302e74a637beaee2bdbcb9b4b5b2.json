{"ast":null,"code":"import _asyncToGenerator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _awaitAsyncGenerator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/awaitAsyncGenerator\";\nimport _wrapAsyncGenerator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/wrapAsyncGenerator\";\nimport _asyncIterator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/asyncIterator\";\nimport { encode, prepare } from '@ipld/dag-pb';\nimport { UnixFS } from 'ipfs-unixfs';\nimport Dir from './dir.js';\nimport persist from './utils/persist.js';\nimport { createHAMT, Bucket } from 'hamt-sharding';\n\nclass DirSharded extends Dir {\n  constructor(props, options) {\n    super(props, options);\n    this._bucket = createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n\n  put(name, value) {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      yield _this3._bucket.put(name, value);\n    })();\n  }\n\n  get(name) {\n    return this._bucket.get(name);\n  }\n\n  childCount() {\n    return this._bucket.leafCount();\n  }\n\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n\n  eachChildSeries() {\n    var _this = this;\n\n    return _wrapAsyncGenerator(function* () {\n      var _iteratorNormalCompletion = true;\n      var _didIteratorError = false;\n\n      var _iteratorError;\n\n      try {\n        for (var _iterator = _asyncIterator(_this._bucket.eachLeafSeries()), _step, _value; _step = yield _awaitAsyncGenerator(_iterator.next()), _iteratorNormalCompletion = _step.done, _value = yield _awaitAsyncGenerator(_step.value), !_iteratorNormalCompletion; _iteratorNormalCompletion = true) {\n          const {\n            key,\n            value\n          } = _value;\n          yield {\n            key,\n            child: value\n          };\n        }\n      } catch (err) {\n        _didIteratorError = true;\n        _iteratorError = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion && _iterator.return != null) {\n            yield _awaitAsyncGenerator(_iterator.return());\n          }\n        } finally {\n          if (_didIteratorError) {\n            throw _iteratorError;\n          }\n        }\n      }\n    })();\n  }\n\n  flush(blockstore) {\n    var _this2 = this;\n\n    return _wrapAsyncGenerator(function* () {\n      var _iteratorNormalCompletion2 = true;\n      var _didIteratorError2 = false;\n\n      var _iteratorError2;\n\n      try {\n        for (var _iterator2 = _asyncIterator(flush(_this2._bucket, blockstore, _this2, _this2.options)), _step2, _value2; _step2 = yield _awaitAsyncGenerator(_iterator2.next()), _iteratorNormalCompletion2 = _step2.done, _value2 = yield _awaitAsyncGenerator(_step2.value), !_iteratorNormalCompletion2; _iteratorNormalCompletion2 = true) {\n          const entry = _value2;\n          yield { ...entry,\n            path: _this2.path\n          };\n        }\n      } catch (err) {\n        _didIteratorError2 = true;\n        _iteratorError2 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion2 && _iterator2.return != null) {\n            yield _awaitAsyncGenerator(_iterator2.return());\n          }\n        } finally {\n          if (_didIteratorError2) {\n            throw _iteratorError2;\n          }\n        }\n      }\n    })();\n  }\n\n}\n\nexport default DirSharded;\n\nfunction flush(_x, _x2, _x3, _x4) {\n  return _flush.apply(this, arguments);\n}\n\nfunction _flush() {\n  _flush = _wrapAsyncGenerator(function* (bucket, blockstore, shardRoot, options) {\n    const children = bucket._children;\n    const links = [];\n    let childrenSize = 0;\n\n    for (let i = 0; i < children.length; i++) {\n      const child = children.get(i);\n\n      if (!child) {\n        continue;\n      }\n\n      const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n\n      if (child instanceof Bucket) {\n        let shard;\n        var _iteratorNormalCompletion3 = true;\n        var _didIteratorError3 = false;\n\n        var _iteratorError3;\n\n        try {\n          for (var _iterator3 = _asyncIterator(yield _awaitAsyncGenerator(flush(child, blockstore, null, options))), _step3, _value3; _step3 = yield _awaitAsyncGenerator(_iterator3.next()), _iteratorNormalCompletion3 = _step3.done, _value3 = yield _awaitAsyncGenerator(_step3.value), !_iteratorNormalCompletion3; _iteratorNormalCompletion3 = true) {\n            const subShard = _value3;\n            shard = subShard;\n          }\n        } catch (err) {\n          _didIteratorError3 = true;\n          _iteratorError3 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion3 && _iterator3.return != null) {\n              yield _awaitAsyncGenerator(_iterator3.return());\n            }\n          } finally {\n            if (_didIteratorError3) {\n              throw _iteratorError3;\n            }\n          }\n        }\n\n        if (!shard) {\n          throw new Error('Could not flush sharded directory, no subshard found');\n        }\n\n        links.push({\n          Name: labelPrefix,\n          Tsize: shard.size,\n          Hash: shard.cid\n        });\n        childrenSize += shard.size;\n      } else if (typeof child.value.flush === 'function') {\n        const dir = child.value;\n        let flushedDir;\n        var _iteratorNormalCompletion4 = true;\n        var _didIteratorError4 = false;\n\n        var _iteratorError4;\n\n        try {\n          for (var _iterator4 = _asyncIterator(dir.flush(blockstore)), _step4, _value4; _step4 = yield _awaitAsyncGenerator(_iterator4.next()), _iteratorNormalCompletion4 = _step4.done, _value4 = yield _awaitAsyncGenerator(_step4.value), !_iteratorNormalCompletion4; _iteratorNormalCompletion4 = true) {\n            const entry = _value4;\n            flushedDir = entry;\n            yield flushedDir;\n          }\n        } catch (err) {\n          _didIteratorError4 = true;\n          _iteratorError4 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion4 && _iterator4.return != null) {\n              yield _awaitAsyncGenerator(_iterator4.return());\n            }\n          } finally {\n            if (_didIteratorError4) {\n              throw _iteratorError4;\n            }\n          }\n        }\n\n        const label = labelPrefix + child.key;\n        links.push({\n          Name: label,\n          Tsize: flushedDir.size,\n          Hash: flushedDir.cid\n        });\n        childrenSize += flushedDir.size;\n      } else {\n        const value = child.value;\n\n        if (!value.cid) {\n          continue;\n        }\n\n        const label = labelPrefix + child.key;\n        const size = value.size;\n        links.push({\n          Name: label,\n          Tsize: size,\n          Hash: value.cid\n        });\n        childrenSize += size;\n      }\n    }\n\n    const data = Uint8Array.from(children.bitField().reverse());\n    const dir = new UnixFS({\n      type: 'hamt-sharded-directory',\n      data,\n      fanout: bucket.tableSize(),\n      hashType: options.hamtHashCode,\n      mtime: shardRoot && shardRoot.mtime,\n      mode: shardRoot && shardRoot.mode\n    });\n    const node = {\n      Data: dir.marshal(),\n      Links: links\n    };\n    const buffer = encode(prepare(node));\n    const cid = yield _awaitAsyncGenerator(persist(buffer, blockstore, options));\n    const size = buffer.length + childrenSize;\n    yield {\n      cid,\n      unixfs: dir,\n      size\n    };\n  });\n  return _flush.apply(this, arguments);\n}","map":{"version":3,"sources":["/Users/sydneybailey/Internship/contract-testing/node_modules/ipfs-unixfs-importer/esm/src/dir-sharded.js"],"names":["encode","prepare","UnixFS","Dir","persist","createHAMT","Bucket","DirSharded","constructor","props","options","_bucket","hashFn","hamtHashFn","bits","hamtBucketBits","put","name","value","get","childCount","leafCount","directChildrenCount","childrenCount","onlyChild","eachChildSeries","eachLeafSeries","key","child","flush","blockstore","entry","path","bucket","shardRoot","children","_children","links","childrenSize","i","length","labelPrefix","toString","toUpperCase","padStart","shard","subShard","Error","push","Name","Tsize","size","Hash","cid","dir","flushedDir","label","data","Uint8Array","from","bitField","reverse","type","fanout","tableSize","hashType","hamtHashCode","mtime","mode","node","Data","marshal","Links","buffer","unixfs"],"mappings":";;;;AAAA,SACEA,MADF,EAEEC,OAFF,QAGO,cAHP;AAIA,SAASC,MAAT,QAAuB,aAAvB;AACA,OAAOC,GAAP,MAAgB,UAAhB;AACA,OAAOC,OAAP,MAAoB,oBAApB;AACA,SACEC,UADF,EAEEC,MAFF,QAGO,eAHP;;AAIA,MAAMC,UAAN,SAAyBJ,GAAzB,CAA6B;AAC3BK,EAAAA,WAAW,CAACC,KAAD,EAAQC,OAAR,EAAiB;AAC1B,UAAMD,KAAN,EAAaC,OAAb;AACA,SAAKC,OAAL,GAAeN,UAAU,CAAC;AACxBO,MAAAA,MAAM,EAAEF,OAAO,CAACG,UADQ;AAExBC,MAAAA,IAAI,EAAEJ,OAAO,CAACK;AAFU,KAAD,CAAzB;AAID;;AACKC,EAAAA,GAAG,CAACC,IAAD,EAAOC,KAAP,EAAc;AAAA;;AAAA;AACrB,YAAM,MAAI,CAACP,OAAL,CAAaK,GAAb,CAAiBC,IAAjB,EAAuBC,KAAvB,CAAN;AADqB;AAEtB;;AACDC,EAAAA,GAAG,CAACF,IAAD,EAAO;AACR,WAAO,KAAKN,OAAL,CAAaQ,GAAb,CAAiBF,IAAjB,CAAP;AACD;;AACDG,EAAAA,UAAU,GAAG;AACX,WAAO,KAAKT,OAAL,CAAaU,SAAb,EAAP;AACD;;AACDC,EAAAA,mBAAmB,GAAG;AACpB,WAAO,KAAKX,OAAL,CAAaY,aAAb,EAAP;AACD;;AACDC,EAAAA,SAAS,GAAG;AACV,WAAO,KAAKb,OAAL,CAAaa,SAAb,EAAP;AACD;;AACMC,EAAAA,eAAe,GAAG;AAAA;;AAAA;AAAA;AAAA;;AAAA;;AAAA;AACvB,4CAAiC,KAAI,CAACd,OAAL,CAAae,cAAb,EAAjC,gOAAgE;AAAA,gBAA/C;AAACC,YAAAA,GAAD;AAAMT,YAAAA;AAAN,WAA+C;AAC9D,gBAAM;AACJS,YAAAA,GADI;AAEJC,YAAAA,KAAK,EAAEV;AAFH,WAAN;AAID;AANsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAOxB;;AACMW,EAAAA,KAAK,CAACC,UAAD,EAAa;AAAA;;AAAA;AAAA;AAAA;;AAAA;;AAAA;AACvB,6CAA0BD,KAAK,CAAC,MAAI,CAAClB,OAAN,EAAemB,UAAf,EAA2B,MAA3B,EAAiC,MAAI,CAACpB,OAAtC,CAA/B,0OAA+E;AAAA,gBAA9DqB,KAA8D;AAC7E,gBAAM,EACJ,GAAGA,KADC;AAEJC,YAAAA,IAAI,EAAE,MAAI,CAACA;AAFP,WAAN;AAID;AANsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAOxB;;AAtC0B;;AAwC7B,eAAezB,UAAf;;SACgBsB,K;;;;;+BAAhB,WAAsBI,MAAtB,EAA8BH,UAA9B,EAA0CI,SAA1C,EAAqDxB,OAArD,EAA8D;AAC5D,UAAMyB,QAAQ,GAAGF,MAAM,CAACG,SAAxB;AACA,UAAMC,KAAK,GAAG,EAAd;AACA,QAAIC,YAAY,GAAG,CAAnB;;AACA,SAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGJ,QAAQ,CAACK,MAA7B,EAAqCD,CAAC,EAAtC,EAA0C;AACxC,YAAMX,KAAK,GAAGO,QAAQ,CAAChB,GAAT,CAAaoB,CAAb,CAAd;;AACA,UAAI,CAACX,KAAL,EAAY;AACV;AACD;;AACD,YAAMa,WAAW,GAAGF,CAAC,CAACG,QAAF,CAAW,EAAX,EAAeC,WAAf,GAA6BC,QAA7B,CAAsC,CAAtC,EAAyC,GAAzC,CAApB;;AACA,UAAIhB,KAAK,YAAYtB,MAArB,EAA6B;AAC3B,YAAIuC,KAAJ;AAD2B;AAAA;;AAAA;;AAAA;AAE3B,0EAAmChB,KAAK,CAACD,KAAD,EAAQE,UAAR,EAAoB,IAApB,EAA0BpB,OAA1B,CAAxC,2OAA4E;AAAA,kBAA3DoC,QAA2D;AAC1ED,YAAAA,KAAK,GAAGC,QAAR;AACD;AAJ0B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAK3B,YAAI,CAACD,KAAL,EAAY;AACV,gBAAM,IAAIE,KAAJ,CAAU,sDAAV,CAAN;AACD;;AACDV,QAAAA,KAAK,CAACW,IAAN,CAAW;AACTC,UAAAA,IAAI,EAAER,WADG;AAETS,UAAAA,KAAK,EAAEL,KAAK,CAACM,IAFJ;AAGTC,UAAAA,IAAI,EAAEP,KAAK,CAACQ;AAHH,SAAX;AAKAf,QAAAA,YAAY,IAAIO,KAAK,CAACM,IAAtB;AACD,OAdD,MAcO,IAAI,OAAOvB,KAAK,CAACV,KAAN,CAAYW,KAAnB,KAA6B,UAAjC,EAA6C;AAClD,cAAMyB,GAAG,GAAG1B,KAAK,CAACV,KAAlB;AACA,YAAIqC,UAAJ;AAFkD;AAAA;;AAAA;;AAAA;AAGlD,+CAA0BD,GAAG,CAACzB,KAAJ,CAAUC,UAAV,CAA1B,0OAAiD;AAAA,kBAAhCC,KAAgC;AAC/CwB,YAAAA,UAAU,GAAGxB,KAAb;AACA,kBAAMwB,UAAN;AACD;AANiD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAOlD,cAAMC,KAAK,GAAGf,WAAW,GAAGb,KAAK,CAACD,GAAlC;AACAU,QAAAA,KAAK,CAACW,IAAN,CAAW;AACTC,UAAAA,IAAI,EAAEO,KADG;AAETN,UAAAA,KAAK,EAAEK,UAAU,CAACJ,IAFT;AAGTC,UAAAA,IAAI,EAAEG,UAAU,CAACF;AAHR,SAAX;AAKAf,QAAAA,YAAY,IAAIiB,UAAU,CAACJ,IAA3B;AACD,OAdM,MAcA;AACL,cAAMjC,KAAK,GAAGU,KAAK,CAACV,KAApB;;AACA,YAAI,CAACA,KAAK,CAACmC,GAAX,EAAgB;AACd;AACD;;AACD,cAAMG,KAAK,GAAGf,WAAW,GAAGb,KAAK,CAACD,GAAlC;AACA,cAAMwB,IAAI,GAAGjC,KAAK,CAACiC,IAAnB;AACAd,QAAAA,KAAK,CAACW,IAAN,CAAW;AACTC,UAAAA,IAAI,EAAEO,KADG;AAETN,UAAAA,KAAK,EAAEC,IAFE;AAGTC,UAAAA,IAAI,EAAElC,KAAK,CAACmC;AAHH,SAAX;AAKAf,QAAAA,YAAY,IAAIa,IAAhB;AACD;AACF;;AACD,UAAMM,IAAI,GAAGC,UAAU,CAACC,IAAX,CAAgBxB,QAAQ,CAACyB,QAAT,GAAoBC,OAApB,EAAhB,CAAb;AACA,UAAMP,GAAG,GAAG,IAAIpD,MAAJ,CAAW;AACrB4D,MAAAA,IAAI,EAAE,wBADe;AAErBL,MAAAA,IAFqB;AAGrBM,MAAAA,MAAM,EAAE9B,MAAM,CAAC+B,SAAP,EAHa;AAIrBC,MAAAA,QAAQ,EAAEvD,OAAO,CAACwD,YAJG;AAKrBC,MAAAA,KAAK,EAAEjC,SAAS,IAAIA,SAAS,CAACiC,KALT;AAMrBC,MAAAA,IAAI,EAAElC,SAAS,IAAIA,SAAS,CAACkC;AANR,KAAX,CAAZ;AAQA,UAAMC,IAAI,GAAG;AACXC,MAAAA,IAAI,EAAEhB,GAAG,CAACiB,OAAJ,EADK;AAEXC,MAAAA,KAAK,EAAEnC;AAFI,KAAb;AAIA,UAAMoC,MAAM,GAAGzE,MAAM,CAACC,OAAO,CAACoE,IAAD,CAAR,CAArB;AACA,UAAMhB,GAAG,8BAASjD,OAAO,CAACqE,MAAD,EAAS3C,UAAT,EAAqBpB,OAArB,CAAhB,CAAT;AACA,UAAMyC,IAAI,GAAGsB,MAAM,CAACjC,MAAP,GAAgBF,YAA7B;AACA,UAAM;AACJe,MAAAA,GADI;AAEJqB,MAAAA,MAAM,EAAEpB,GAFJ;AAGJH,MAAAA;AAHI,KAAN;AAKD,G","sourcesContent":["import {\n  encode,\n  prepare\n} from '@ipld/dag-pb';\nimport { UnixFS } from 'ipfs-unixfs';\nimport Dir from './dir.js';\nimport persist from './utils/persist.js';\nimport {\n  createHAMT,\n  Bucket\n} from 'hamt-sharding';\nclass DirSharded extends Dir {\n  constructor(props, options) {\n    super(props, options);\n    this._bucket = createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n  async put(name, value) {\n    await this._bucket.put(name, value);\n  }\n  get(name) {\n    return this._bucket.get(name);\n  }\n  childCount() {\n    return this._bucket.leafCount();\n  }\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n  async *eachChildSeries() {\n    for await (const {key, value} of this._bucket.eachLeafSeries()) {\n      yield {\n        key,\n        child: value\n      };\n    }\n  }\n  async *flush(blockstore) {\n    for await (const entry of flush(this._bucket, blockstore, this, this.options)) {\n      yield {\n        ...entry,\n        path: this.path\n      };\n    }\n  }\n}\nexport default DirSharded;\nasync function* flush(bucket, blockstore, shardRoot, options) {\n  const children = bucket._children;\n  const links = [];\n  let childrenSize = 0;\n  for (let i = 0; i < children.length; i++) {\n    const child = children.get(i);\n    if (!child) {\n      continue;\n    }\n    const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n    if (child instanceof Bucket) {\n      let shard;\n      for await (const subShard of await flush(child, blockstore, null, options)) {\n        shard = subShard;\n      }\n      if (!shard) {\n        throw new Error('Could not flush sharded directory, no subshard found');\n      }\n      links.push({\n        Name: labelPrefix,\n        Tsize: shard.size,\n        Hash: shard.cid\n      });\n      childrenSize += shard.size;\n    } else if (typeof child.value.flush === 'function') {\n      const dir = child.value;\n      let flushedDir;\n      for await (const entry of dir.flush(blockstore)) {\n        flushedDir = entry;\n        yield flushedDir;\n      }\n      const label = labelPrefix + child.key;\n      links.push({\n        Name: label,\n        Tsize: flushedDir.size,\n        Hash: flushedDir.cid\n      });\n      childrenSize += flushedDir.size;\n    } else {\n      const value = child.value;\n      if (!value.cid) {\n        continue;\n      }\n      const label = labelPrefix + child.key;\n      const size = value.size;\n      links.push({\n        Name: label,\n        Tsize: size,\n        Hash: value.cid\n      });\n      childrenSize += size;\n    }\n  }\n  const data = Uint8Array.from(children.bitField().reverse());\n  const dir = new UnixFS({\n    type: 'hamt-sharded-directory',\n    data,\n    fanout: bucket.tableSize(),\n    hashType: options.hamtHashCode,\n    mtime: shardRoot && shardRoot.mtime,\n    mode: shardRoot && shardRoot.mode\n  });\n  const node = {\n    Data: dir.marshal(),\n    Links: links\n  };\n  const buffer = encode(prepare(node));\n  const cid = await persist(buffer, blockstore, options);\n  const size = buffer.length + childrenSize;\n  yield {\n    cid,\n    unixfs: dir,\n    size\n  };\n}"]},"metadata":{},"sourceType":"module"}