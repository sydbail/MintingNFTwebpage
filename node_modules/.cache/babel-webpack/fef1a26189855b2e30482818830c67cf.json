{"ast":null,"code":"'use strict';\n\nvar _awaitAsyncGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/awaitAsyncGenerator\").default;\n\nvar _wrapAsyncGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/wrapAsyncGenerator\").default;\n\nvar _asyncIterator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncIterator\").default;\n\nconst createLock = require('./utils/create-lock');\n\nconst isIpfs = require('is-ipfs');\n/**\n * @typedef {import('multiformats/hashes/interface').MultihashHasher} MultihashHasher\n * @typedef {import('ipfs-core-utils/src/multihashes')} Multihashes\n * @typedef {import('ipfs-repo').IPFSRepo} IPFSRepo\n *\n * @typedef {object} MfsContext\n * @property {IPFSRepo} repo\n * @property {Multihashes} hashers\n */\n\n/**\n * These operations are read-locked at the function level and will execute simultaneously\n *\n * @type {Record<string, any>}\n */\n\n\nconst readOperations = {\n  stat: require('./stat')\n};\n/**\n * These operations are locked at the function level and will execute in series\n *\n * @type {Record<string, any>}\n */\n\nconst writeOperations = {\n  chmod: require('./chmod'),\n  cp: require('./cp'),\n  flush: require('./flush'),\n  mkdir: require('./mkdir'),\n  mv: require('./mv'),\n  rm: require('./rm'),\n  touch: require('./touch')\n};\n/**\n * These operations are asynchronous and manage their own locking\n *\n * @type {Record<string, any>}\n */\n\nconst unwrappedOperations = {\n  write: require('./write'),\n  read: require('./read'),\n  ls: require('./ls')\n};\n/**\n * @param {object} arg\n * @param {MfsContext} arg.options\n * @param {*} arg.mfs\n * @param {*} arg.operations\n * @param {*} arg.lock\n */\n\nconst wrap = ({\n  options,\n  mfs,\n  operations,\n  lock\n}) => {\n  Object.keys(operations).forEach(key => {\n    mfs[key] = lock(operations[key](options));\n  });\n};\n\nconst defaultOptions = {\n  repoOwner: true,\n  repo: null\n};\n/**\n * @param {object} options\n * @param {IPFSRepo} options.repo\n * @param {boolean} options.repoOwner\n * @param {Multihashes} options.hashers\n */\n\nfunction createMfs(options) {\n  const {\n    repoOwner\n  } = Object.assign({}, defaultOptions || {}, options);\n  const lock = createLock(repoOwner);\n  /**\n   * @param {(fn: (...args: any) => any) => (...args: any) => any} operation\n   */\n\n  const readLock = operation => {\n    return lock.readLock(operation);\n  };\n  /**\n   * @param {(fn: (...args: any) => any) => (...args: any) => any} operation\n   */\n\n\n  const writeLock = operation => {\n    return lock.writeLock(operation);\n  };\n  /** @type {Record<string, any>} */\n\n\n  const mfs = {};\n  wrap({\n    options,\n    mfs,\n    operations: readOperations,\n    lock: readLock\n  });\n  wrap({\n    options,\n    mfs,\n    operations: writeOperations,\n    lock: writeLock\n  });\n  Object.keys(unwrappedOperations).forEach(key => {\n    mfs[key] = unwrappedOperations[key](options);\n  });\n  return mfs;\n}\n/**\n * @param {object} context\n * @param {IPFSRepo} context.repo\n * @param {import('../../types').Preload} context.preload\n * @param {import('..').Options} context.options\n * @param {Multihashes} context.hashers\n * @returns {import('ipfs-core-types/src/files').API}\n */\n\n\nmodule.exports = ({\n  repo,\n  preload,\n  hashers,\n  options: constructorOptions\n}) => {\n  const methods = createMfs({\n    repo,\n    repoOwner: Boolean(constructorOptions.repoOwner),\n    hashers\n  });\n  /**\n   * @param {any} fn\n   */\n\n  const withPreload = fn => {\n    /**\n     * @param  {...any} args\n     */\n    const wrapped = (...args) => {\n      // @ts-ignore cannot derive type of arg\n      const paths = args.filter(arg => isIpfs.ipfsPath(arg) || isIpfs.cid(arg));\n\n      if (paths.length) {\n        const options = args[args.length - 1]; // @ts-ignore it's a PreloadOptions, honest\n\n        if (options && options.preload !== false) {\n          paths.forEach(path => preload(path));\n        }\n      }\n\n      return fn(...args);\n    };\n\n    return wrapped;\n  };\n\n  return { ...methods,\n    chmod: methods.chmod,\n    cp: withPreload(methods.cp),\n    mkdir: methods.mkdir,\n    stat: withPreload(methods.stat),\n    rm: methods.rm,\n    read: withPreload(methods.read),\n    touch: methods.touch,\n    write: methods.write,\n    mv: withPreload(methods.mv),\n    flush: methods.flush,\n    ls: withPreload( /*#__PURE__*/function () {\n      var _ref = _wrapAsyncGenerator(function* (\n      /** @type {...any} */\n      ...args) {\n        var _iteratorNormalCompletion = true;\n        var _didIteratorError = false;\n\n        var _iteratorError;\n\n        try {\n          for (var _iterator = _asyncIterator(methods.ls(...args)), _step, _value; _step = yield _awaitAsyncGenerator(_iterator.next()), _iteratorNormalCompletion = _step.done, _value = yield _awaitAsyncGenerator(_step.value), !_iteratorNormalCompletion; _iteratorNormalCompletion = true) {\n            const file = _value;\n            yield { ...file,\n              size: file.size || 0\n            };\n          }\n        } catch (err) {\n          _didIteratorError = true;\n          _iteratorError = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion && _iterator.return != null) {\n              yield _awaitAsyncGenerator(_iterator.return());\n            }\n          } finally {\n            if (_didIteratorError) {\n              throw _iteratorError;\n            }\n          }\n        }\n      });\n\n      return function () {\n        return _ref.apply(this, arguments);\n      };\n    }())\n  };\n};","map":null,"metadata":{},"sourceType":"script"}