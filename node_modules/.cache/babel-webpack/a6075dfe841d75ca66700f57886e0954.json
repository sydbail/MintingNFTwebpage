{"ast":null,"code":"import _asyncToGenerator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _awaitAsyncGenerator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/awaitAsyncGenerator\";\nimport _wrapAsyncGenerator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/wrapAsyncGenerator\";\nimport _asyncIterator from \"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/esm/asyncIterator\";\nimport { encode, prepare } from '@ipld/dag-pb';\nimport { UnixFS } from 'ipfs-unixfs';\nimport Dir from './dir.js';\nimport persist from './utils/persist.js';\nimport { createHAMT, Bucket } from 'hamt-sharding';\n\nclass DirSharded extends Dir {\n  constructor(props, options) {\n    super(props, options);\n    this._bucket = createHAMT({\n      hashFn: options.hamtHashFn,\n      bits: options.hamtBucketBits\n    });\n  }\n\n  put(name, value) {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      yield _this3._bucket.put(name, value);\n    })();\n  }\n\n  get(name) {\n    return this._bucket.get(name);\n  }\n\n  childCount() {\n    return this._bucket.leafCount();\n  }\n\n  directChildrenCount() {\n    return this._bucket.childrenCount();\n  }\n\n  onlyChild() {\n    return this._bucket.onlyChild();\n  }\n\n  eachChildSeries() {\n    var _this = this;\n\n    return _wrapAsyncGenerator(function* () {\n      var _iteratorNormalCompletion = true;\n      var _didIteratorError = false;\n\n      var _iteratorError;\n\n      try {\n        for (var _iterator = _asyncIterator(_this._bucket.eachLeafSeries()), _step, _value; _step = yield _awaitAsyncGenerator(_iterator.next()), _iteratorNormalCompletion = _step.done, _value = yield _awaitAsyncGenerator(_step.value), !_iteratorNormalCompletion; _iteratorNormalCompletion = true) {\n          const {\n            key,\n            value\n          } = _value;\n          yield {\n            key,\n            child: value\n          };\n        }\n      } catch (err) {\n        _didIteratorError = true;\n        _iteratorError = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion && _iterator.return != null) {\n            yield _awaitAsyncGenerator(_iterator.return());\n          }\n        } finally {\n          if (_didIteratorError) {\n            throw _iteratorError;\n          }\n        }\n      }\n    })();\n  }\n\n  flush(blockstore) {\n    var _this2 = this;\n\n    return _wrapAsyncGenerator(function* () {\n      var _iteratorNormalCompletion2 = true;\n      var _didIteratorError2 = false;\n\n      var _iteratorError2;\n\n      try {\n        for (var _iterator2 = _asyncIterator(flush(_this2._bucket, blockstore, _this2, _this2.options)), _step2, _value2; _step2 = yield _awaitAsyncGenerator(_iterator2.next()), _iteratorNormalCompletion2 = _step2.done, _value2 = yield _awaitAsyncGenerator(_step2.value), !_iteratorNormalCompletion2; _iteratorNormalCompletion2 = true) {\n          const entry = _value2;\n          yield { ...entry,\n            path: _this2.path\n          };\n        }\n      } catch (err) {\n        _didIteratorError2 = true;\n        _iteratorError2 = err;\n      } finally {\n        try {\n          if (!_iteratorNormalCompletion2 && _iterator2.return != null) {\n            yield _awaitAsyncGenerator(_iterator2.return());\n          }\n        } finally {\n          if (_didIteratorError2) {\n            throw _iteratorError2;\n          }\n        }\n      }\n    })();\n  }\n\n}\n\nexport default DirSharded;\n\nfunction flush(_x, _x2, _x3, _x4) {\n  return _flush.apply(this, arguments);\n}\n\nfunction _flush() {\n  _flush = _wrapAsyncGenerator(function* (bucket, blockstore, shardRoot, options) {\n    const children = bucket._children;\n    const links = [];\n    let childrenSize = 0;\n\n    for (let i = 0; i < children.length; i++) {\n      const child = children.get(i);\n\n      if (!child) {\n        continue;\n      }\n\n      const labelPrefix = i.toString(16).toUpperCase().padStart(2, '0');\n\n      if (child instanceof Bucket) {\n        let shard;\n        var _iteratorNormalCompletion3 = true;\n        var _didIteratorError3 = false;\n\n        var _iteratorError3;\n\n        try {\n          for (var _iterator3 = _asyncIterator(yield _awaitAsyncGenerator(flush(child, blockstore, null, options))), _step3, _value3; _step3 = yield _awaitAsyncGenerator(_iterator3.next()), _iteratorNormalCompletion3 = _step3.done, _value3 = yield _awaitAsyncGenerator(_step3.value), !_iteratorNormalCompletion3; _iteratorNormalCompletion3 = true) {\n            const subShard = _value3;\n            shard = subShard;\n          }\n        } catch (err) {\n          _didIteratorError3 = true;\n          _iteratorError3 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion3 && _iterator3.return != null) {\n              yield _awaitAsyncGenerator(_iterator3.return());\n            }\n          } finally {\n            if (_didIteratorError3) {\n              throw _iteratorError3;\n            }\n          }\n        }\n\n        if (!shard) {\n          throw new Error('Could not flush sharded directory, no subshard found');\n        }\n\n        links.push({\n          Name: labelPrefix,\n          Tsize: shard.size,\n          Hash: shard.cid\n        });\n        childrenSize += shard.size;\n      } else if (typeof child.value.flush === 'function') {\n        const dir = child.value;\n        let flushedDir;\n        var _iteratorNormalCompletion4 = true;\n        var _didIteratorError4 = false;\n\n        var _iteratorError4;\n\n        try {\n          for (var _iterator4 = _asyncIterator(dir.flush(blockstore)), _step4, _value4; _step4 = yield _awaitAsyncGenerator(_iterator4.next()), _iteratorNormalCompletion4 = _step4.done, _value4 = yield _awaitAsyncGenerator(_step4.value), !_iteratorNormalCompletion4; _iteratorNormalCompletion4 = true) {\n            const entry = _value4;\n            flushedDir = entry;\n            yield flushedDir;\n          }\n        } catch (err) {\n          _didIteratorError4 = true;\n          _iteratorError4 = err;\n        } finally {\n          try {\n            if (!_iteratorNormalCompletion4 && _iterator4.return != null) {\n              yield _awaitAsyncGenerator(_iterator4.return());\n            }\n          } finally {\n            if (_didIteratorError4) {\n              throw _iteratorError4;\n            }\n          }\n        }\n\n        const label = labelPrefix + child.key;\n        links.push({\n          Name: label,\n          Tsize: flushedDir.size,\n          Hash: flushedDir.cid\n        });\n        childrenSize += flushedDir.size;\n      } else {\n        const value = child.value;\n\n        if (!value.cid) {\n          continue;\n        }\n\n        const label = labelPrefix + child.key;\n        const size = value.size;\n        links.push({\n          Name: label,\n          Tsize: size,\n          Hash: value.cid\n        });\n        childrenSize += size;\n      }\n    }\n\n    const data = Uint8Array.from(children.bitField().reverse());\n    const dir = new UnixFS({\n      type: 'hamt-sharded-directory',\n      data,\n      fanout: bucket.tableSize(),\n      hashType: options.hamtHashCode,\n      mtime: shardRoot && shardRoot.mtime,\n      mode: shardRoot && shardRoot.mode\n    });\n    const node = {\n      Data: dir.marshal(),\n      Links: links\n    };\n    const buffer = encode(prepare(node));\n    const cid = yield _awaitAsyncGenerator(persist(buffer, blockstore, options));\n    const size = buffer.length + childrenSize;\n    yield {\n      cid,\n      unixfs: dir,\n      size\n    };\n  });\n  return _flush.apply(this, arguments);\n}","map":null,"metadata":{},"sourceType":"module"}