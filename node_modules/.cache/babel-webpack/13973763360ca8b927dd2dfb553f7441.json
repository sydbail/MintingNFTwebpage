{"ast":null,"code":"'use strict';\n\nvar _wrapAsyncGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/wrapAsyncGenerator\").default;\n\nvar _awaitAsyncGenerator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/awaitAsyncGenerator\").default;\n\nvar _asyncIterator = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncIterator\").default;\n\nvar _asyncGeneratorDelegate = require(\"/Users/sydneybailey/Internship/contract-testing/node_modules/@babel/runtime/helpers/asyncGeneratorDelegate\").default;\n\nconst {\n  exporter,\n  recursive\n} = require('ipfs-unixfs-exporter');\n\nconst errCode = require('err-code');\n\nconst {\n  normalizeCidPath\n} = require('../utils');\n\nconst withTimeoutOption = require('ipfs-core-utils/src/with-timeout-option');\n\nconst {\n  CID\n} = require('multiformats/cid');\n\nconst {\n  pack\n} = require('it-tar');\n\nconst {\n  pipe\n} = require('it-pipe');\n\nconst {\n  gzip\n} = require('pako');\n\nconst map = require('it-map');\n\nconst toBuffer = require('it-to-buffer'); // https://www.gnu.org/software/gzip/manual/gzip.html\n\n\nconst DEFAULT_COMPRESSION_LEVEL = 6;\n/**\n * @typedef {Object} Context\n * @property {import('ipfs-repo').IPFSRepo} repo\n * @property {import('../types').Preload} preload\n *\n * @param {Context} context\n */\n\nmodule.exports = function ({\n  repo,\n  preload\n}) {\n  /**\n   * @type {import('ipfs-core-types/src/root').API[\"get\"]}\n   */\n  function get(_x) {\n    return _get.apply(this, arguments);\n  }\n\n  function _get() {\n    _get = _wrapAsyncGenerator(function* (ipfsPath, options = {}) {\n      if (options.compressionLevel < 0 || options.compressionLevel > 9) {\n        throw errCode(new Error('Compression level must be between 1 and 9'), 'ERR_INVALID_PARAMS');\n      }\n\n      if (options.preload !== false) {\n        let pathComponents;\n\n        try {\n          pathComponents = normalizeCidPath(ipfsPath).split('/');\n        } catch (err) {\n          throw errCode(err, 'ERR_INVALID_PATH');\n        }\n\n        preload(CID.parse(pathComponents[0]));\n      }\n\n      const ipfsPathOrCid = CID.asCID(ipfsPath) || ipfsPath;\n      const file = yield _awaitAsyncGenerator(exporter(ipfsPathOrCid, repo.blocks, options));\n\n      if (file.type === 'file' || file.type === 'raw') {\n        const args = [];\n\n        if (!options.compress || options.archive === true) {\n          args.push([{\n            header: {\n              name: file.path,\n              mode: file.type === 'file' && file.unixfs.mode,\n              mtime: file.type === 'file' && file.unixfs.mtime ? new Date(file.unixfs.mtime.secs * 1000) : undefined,\n              size: file.size,\n              type: 'file'\n            },\n            body: file.content()\n          }], pack(),\n          /**\n           * @param {AsyncIterable<Uint8Array>} source\n           */\n          source => map(source, buf => buf.slice()));\n        } else {\n          args.push(file.content);\n        }\n\n        if (options.compress) {\n          args.push(\n          /*#__PURE__*/\n\n          /**\n           * @param {AsyncIterable<Uint8Array>} source\n           */\n          function () {\n            var _ref = _wrapAsyncGenerator(function* (source) {\n              const buf = yield _awaitAsyncGenerator(toBuffer(source));\n              yield gzip(buf, {\n                level: options.compressionLevel || DEFAULT_COMPRESSION_LEVEL\n              });\n            });\n\n            return function (_x2) {\n              return _ref.apply(this, arguments);\n            };\n          }());\n        } // @ts-ignore cannot derive type\n\n\n        yield* _asyncGeneratorDelegate(_asyncIterator(pipe(...args)), _awaitAsyncGenerator);\n        return;\n      }\n\n      if (file.type === 'directory') {\n        /** @type {any[]} */\n        const args = [recursive(ipfsPathOrCid, repo.blocks, options),\n        /*#__PURE__*/\n\n        /**\n         * @param {AsyncIterable<import('ipfs-unixfs-exporter').UnixFSEntry>} source\n         */\n        function () {\n          var _ref2 = _wrapAsyncGenerator(function* (source) {\n            var _iteratorNormalCompletion = true;\n            var _didIteratorError = false;\n\n            var _iteratorError;\n\n            try {\n              for (var _iterator = _asyncIterator(source), _step, _value; _step = yield _awaitAsyncGenerator(_iterator.next()), _iteratorNormalCompletion = _step.done, _value = yield _awaitAsyncGenerator(_step.value), !_iteratorNormalCompletion; _iteratorNormalCompletion = true) {\n                const entry = _value;\n\n                /** @type {import('it-tar').TarImportCandidate} */\n                const output = {\n                  header: {\n                    name: entry.path,\n                    size: entry.size\n                  }\n                };\n\n                if (entry.type === 'file') {\n                  output.header.type = 'file';\n                  output.header.mode = entry.unixfs.mode != null ? entry.unixfs.mode : undefined;\n                  output.header.mtime = entry.unixfs.mtime ? new Date(entry.unixfs.mtime.secs * 1000) : undefined;\n                  output.body = entry.content();\n                } else if (entry.type === 'raw') {\n                  output.header.type = 'file';\n                  output.body = entry.content();\n                } else if (entry.type === 'directory') {\n                  output.header.type = 'directory';\n                  output.header.mode = entry.unixfs.mode != null ? entry.unixfs.mode : undefined;\n                  output.header.mtime = entry.unixfs.mtime ? new Date(entry.unixfs.mtime.secs * 1000) : undefined;\n                } else {\n                  throw errCode(new Error('Not a UnixFS node'), 'ERR_NOT_UNIXFS');\n                }\n\n                yield output;\n              }\n            } catch (err) {\n              _didIteratorError = true;\n              _iteratorError = err;\n            } finally {\n              try {\n                if (!_iteratorNormalCompletion && _iterator.return != null) {\n                  yield _awaitAsyncGenerator(_iterator.return());\n                }\n              } finally {\n                if (_didIteratorError) {\n                  throw _iteratorError;\n                }\n              }\n            }\n          });\n\n          return function (_x3) {\n            return _ref2.apply(this, arguments);\n          };\n        }(), pack(),\n        /**\n         * @param {AsyncIterable<Uint8Array>} source\n         */\n        source => map(source, buf => buf.slice())];\n\n        if (options.compress) {\n          if (!options.archive) {\n            throw errCode(new Error('file is not regular'), 'ERR_INVALID_PATH');\n          }\n\n          if (options.compress) {\n            args.push(\n            /*#__PURE__*/\n\n            /**\n             * @param {AsyncIterable<Uint8Array>} source\n             */\n            function () {\n              var _ref3 = _wrapAsyncGenerator(function* (source) {\n                const buf = yield _awaitAsyncGenerator(toBuffer(source));\n                yield gzip(buf, {\n                  level: options.compressionLevel || DEFAULT_COMPRESSION_LEVEL\n                });\n              });\n\n              return function (_x4) {\n                return _ref3.apply(this, arguments);\n              };\n            }());\n          }\n        } // @ts-ignore cannot derive type\n\n\n        yield* _asyncGeneratorDelegate(_asyncIterator(pipe(...args)), _awaitAsyncGenerator);\n        return;\n      }\n\n      throw errCode(new Error('Not a UnixFS node'), 'ERR_NOT_UNIXFS');\n    });\n    return _get.apply(this, arguments);\n  }\n\n  return withTimeoutOption(get);\n};","map":null,"metadata":{},"sourceType":"script"}